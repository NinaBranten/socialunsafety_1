<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2025-06-18" />

<title>LCA binair</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>


<link rel="stylesheet" href="tweaks.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="Data_preparation.html">Data preparation</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    LCAs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LCA_final_model.html">final model</a>
    </li>
    <li>
      <a href="LCA_binair.html">binary</a>
    </li>
    <li>
      <a href="LCA_listwise.html">listwise</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    MAIHDA
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="MAIHDA_final_model.html">final model</a>
    </li>
    <li>
      <a href="MAIHDA_binary.html">binary</a>
    </li>
    <li>
      <a href="Items_seperate.html">items separate</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ninabranten/socialunsafety_1">
    <span class="fab fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">LCA binair</h1>
<h4 class="date">2025-06-18</h4>

</div>


<pre class="r"><code>library(&quot;formatR&quot;)
library(&quot;foreign&quot;)
library(&quot;ggplot2&quot;)
library(&quot;lme4&quot;)
library(&quot;poLCA&quot;)
library(&quot;reprex&quot;)
library(&quot;tidyr&quot;)
library(&quot;klippy&quot;)
library(&quot;dplyr&quot;)
library(&quot;haven&quot;)
library(&quot;psych&quot;)</code></pre>
<p><br><br> <strong>Loading the data</strong></p>
<pre class="r"><code>NEA2022 &lt;- readRDS(&quot;data/processed/NEA1009.rds&quot;)

attach(NEA2022)
set.seed(123)</code></pre>
<p><br><br> <strong>Recoding into binary variables</strong></p>
<pre class="r"><code>table(NEA2022$pesten_col)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 28924   543   139    38</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(bul_c = case_when(
    pesten_col == 1 ~ 1,
    pesten_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$bul_c)</code></pre>
<pre><code>## 
##     1     2 
## 28924   720</code></pre>
<pre class="r"><code>table(NEA2022$pesten_leid)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29301   207   110    40</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(bul_s = case_when(
    pesten_leid == 1 ~ 1,
    pesten_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$bul_s)</code></pre>
<pre><code>## 
##     1     2 
## 29301   357</code></pre>
<pre class="r"><code>table(NEA2022$intimidation_col)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29330   337    35    26</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(int_c = case_when(
    intimidation_col == 1 ~ 1,
    intimidation_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$int_c)</code></pre>
<pre><code>## 
##     1     2 
## 29330   398</code></pre>
<pre class="r"><code>table(NEA2022$intimidation_leid)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29262   331    97    34</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(int_s = case_when(
    intimidation_leid == 1 ~ 1,
    intimidation_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$int_s)</code></pre>
<pre><code>## 
##     1     2 
## 29262   462</code></pre>
<pre class="r"><code>table(NEA2022$seks_col)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29468   233    33    13</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(sex_c = case_when(
    seks_col == 1 ~ 1,
    seks_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$sex_c)</code></pre>
<pre><code>## 
##     1     2 
## 29468   279</code></pre>
<pre class="r"><code>table(NEA2022$seks_leid)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29667    67    10    11</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(sex_s = case_when(
    seks_leid == 1 ~ 1,
    seks_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$sex_s)</code></pre>
<pre><code>## 
##     1     2 
## 29667    88</code></pre>
<pre class="r"><code>table(NEA2022$geweld_col)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29761    23     5     4</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(vio_c = case_when(
    geweld_col == 1 ~ 1,
    geweld_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$vio_c)</code></pre>
<pre><code>## 
##     1     2 
## 29761    32</code></pre>
<pre class="r"><code>table(NEA2022$geweld_leid)</code></pre>
<pre><code>## 
##     1     2     3     4 
## 29784     5     5     3</code></pre>
<pre class="r"><code>NEA2022 &lt;- NEA2022 %&gt;%
  mutate(vio_s = case_when(
    geweld_leid == 1 ~ 1,
    geweld_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$vio_s)</code></pre>
<pre><code>## 
##     1     2 
## 29784    13</code></pre>
<div id="latent-class-analysis" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Latent class
analysis</h1>
<pre class="r"><code>attach(NEA2022)
data_b &lt;- data.frame(bul_c, bul_s, int_c, int_s, vio_c, vio_s, sex_c, sex_s, conflict_col, conflict_leid, steunleid_RR, steuncol_RR, psyveil_RR)

items_b &lt;- cbind(bul_c, bul_s, int_c, int_s, vio_c, vio_s, sex_c, sex_s, conflict_col, conflict_leid, steunleid_RR, steuncol_RR, psyveil_RR) ~ 1</code></pre>
<div id="model1" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Model1</h2>
<pre class="r"><code>model1_b &lt;- poLCA(items_b, data_b, nclass = 1, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9757 0.0243
## 
## $bul_s
##           Pr(1) Pr(2)
## class 1:  0.988 0.012
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9866 0.0134
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9845 0.0155
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  0.9989 0.0011
## 
## $vio_s
##            Pr(1) Pr(2)
## class 1:  0.9996 4e-04
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9906 0.0094
## 
## $sex_s
##           Pr(1) Pr(2)
## class 1:  0.997 0.003
## 
## $conflict_col
##            Pr(1)  Pr(2) Pr(3)
## class 1:  0.8117 0.1653 0.023
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.8832 0.0969 0.0199
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.2424 0.5728 0.1551 0.0297
## 
## $steuncol_RR
##           Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.339 0.5915 0.0635 0.0059
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3) Pr(4)  Pr(5)
## class 1:  0.1413 0.5359 0.2546 0.052 0.0162
## 
## Estimated class population shares 
##  1 
##  
## Predicted class memberships (by modal posterior prob.) 
##  1 
##  
## ========================================================= 
## Fit for 1 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 22 
## residual degrees of freedom: 29901 
## maximum log-likelihood: -133044 
##  
## AIC(1): 266132.1
## BIC(1): 266314.8
## G^2(1): 32277.27 (Likelihood ratio/deviance statistic) 
## X^2(1): 1.608346e+16 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model2" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Model2</h2>
<pre class="r"><code>model2_b &lt;- poLCA(items_b, data_b, nclass = 2, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -125603.7 ... best llik = -125603.7
## Model 2: llik = -125603.7 ... best llik = -125603.7
## Model 3: llik = -125603.7 ... best llik = -125603.7
## Model 4: llik = -125603.7 ... best llik = -125603.7
## Model 5: llik = -125603.7 ... best llik = -125603.7
## Model 6: llik = -125603.7 ... best llik = -125603.7
## Model 7: llik = -125603.7 ... best llik = -125603.7
## Model 8: llik = -125603.7 ... best llik = -125603.7
## Model 9: llik = -125603.7 ... best llik = -125603.7
## Model 10: llik = -125603.7 ... best llik = -125603.7
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9117 0.0883
## class 2:  0.9975 0.0025
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9532 0.0468
## class 2:  0.9998 0.0002
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9545 0.0455
## class 2:  0.9977 0.0023
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9392 0.0608
## class 2:  1.0000 0.0000
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  0.9958 0.0042
## class 2:  1.0000 0.0000
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  0.9983 0.0017
## class 2:  1.0000 0.0000
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9752 0.0248
## class 2:  0.9959 0.0041
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9902 0.0098
## class 2:  0.9994 0.0006
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.5673 0.3563 0.0764
## class 2:  0.8960 0.0994 0.0046
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.6147 0.3116 0.0737
## class 2:  0.9760 0.0227 0.0013
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.0327 0.4125 0.4427 0.1121
## class 2:  0.3157 0.6289 0.0545 0.0009
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3) Pr(4)
## class 1:  0.1543 0.6260 0.1967 0.023
## class 2:  0.4033 0.5795 0.0172 0.000
## 
## $psyveil_RR
##            Pr(1)  Pr(2) Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0192 0.2990 0.478 0.1747 0.0291
## class 2:  0.1837 0.6183 0.177 0.0093 0.0117
## 
## Estimated class population shares 
##  0.2575 0.7425 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.2344 0.7656 
##  
## ========================================================= 
## Fit for 2 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 45 
## residual degrees of freedom: 29878 
## maximum log-likelihood: -125603.7 
##  
## AIC(2): 251297.5
## BIC(2): 251671.3
## G^2(2): 18489.47 (Likelihood ratio/deviance statistic) 
## X^2(2): 117803506819 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model3" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Model3</h2>
<pre class="r"><code>model3_b &lt;- poLCA(items_b, data_b, nclass = 3, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -121170.3 ... best llik = -121170.3
## Model 2: llik = -121170.3 ... best llik = -121170.3
## Model 3: llik = -121170.3 ... best llik = -121170.3
## Model 4: llik = -121170.3 ... best llik = -121170.3
## Model 5: llik = -121170.3 ... best llik = -121170.3
## Model 6: llik = -121170.3 ... best llik = -121170.3
## Model 7: llik = -121170.3 ... best llik = -121170.3
## Model 8: llik = -121170.3 ... best llik = -121170.3
## Model 9: llik = -121170.3 ... best llik = -121170.3
## Model 10: llik = -121170.3 ... best llik = -121170.3
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9943 0.0057
## class 2:  0.8728 0.1272
## class 3:  0.9971 0.0029
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9255 0.0745
## class 3:  0.9991 0.0009
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9974 0.0026
## class 2:  0.9318 0.0682
## class 3:  0.9961 0.0039
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9999 0.0001
## class 2:  0.9043 0.0957
## class 3:  0.9994 0.0006
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9934 0.0066
## class 3:  1.0000 0.0000
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9973 0.0027
## class 3:  1.0000 0.0000
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9954 0.0046
## class 2:  0.9660 0.0340
## class 3:  0.9951 0.0049
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9993 0.0007
## class 2:  0.9851 0.0149
## class 3:  0.9993 0.0007
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.8638 0.1316 0.0046
## class 2:  0.4787 0.4091 0.1122
## class 3:  0.9038 0.0868 0.0094
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.9528 0.0472 0.0000
## class 2:  0.4843 0.4001 0.1156
## class 3:  0.9765 0.0181 0.0055
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.0753 0.7996 0.1211 0.0040
## class 2:  0.0441 0.2967 0.4940 0.1651
## class 3:  0.7901 0.1982 0.0100 0.0017
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.1957 0.7607 0.0431 0.0005
## class 2:  0.1835 0.5516 0.2300 0.0349
## class 3:  0.7974 0.2002 0.0023 0.0000
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0298 0.6620 0.2871 0.0210 0.0000
## class 2:  0.0295 0.2461 0.4451 0.2322 0.0472
## class 3:  0.4911 0.4187 0.0471 0.0077 0.0355
## 
## Estimated class population shares 
##  0.5969 0.1614 0.2417 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.6454 0.1472 0.2074 
##  
## ========================================================= 
## Fit for 3 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 68 
## residual degrees of freedom: 29855 
## maximum log-likelihood: -121170.3 
##  
## AIC(3): 242476.6
## BIC(3): 243041.4
## G^2(3): 9919.044 (Likelihood ratio/deviance statistic) 
## X^2(3): 2030513620 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model4" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Model4</h2>
<pre class="r"><code>model4_b &lt;- poLCA(items_b, data_b, nclass = 4, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -120317.3 ... best llik = -120317.3
## Model 2: llik = -120317.3 ... best llik = -120317.3
## Model 3: llik = -120317.3 ... best llik = -120317.3
## Model 4: llik = -120317.3 ... best llik = -120317.3
## Model 5: llik = -120317.3 ... best llik = -120317.3
## Model 6: llik = -120317.3 ... best llik = -120317.3
## Model 7: llik = -120317.3 ... best llik = -120317.3
## Model 8: llik = -120317.3 ... best llik = -120317.3
## Model 9: llik = -120425.5 ... best llik = -120317.3
## Model 10: llik = -120425.5 ... best llik = -120317.3
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9982 0.0018
## class 2:  0.7513 0.2487
## class 3:  0.9839 0.0161
## class 4:  0.9928 0.0072
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9993 0.0007
## class 2:  0.8364 0.1636
## class 3:  0.9971 0.0029
## class 4:  1.0000 0.0000
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9969 0.0031
## class 2:  0.8554 0.1446
## class 3:  0.9972 0.0028
## class 4:  0.9961 0.0039
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.8174 0.1826
## class 3:  0.9852 0.0148
## class 4:  0.9998 0.0002
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9861 0.0139
## class 3:  1.0000 0.0000
## class 4:  0.9998 0.0002
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9938 0.0062
## class 3:  1.0000 0.0000
## class 4:  1.0000 0.0000
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9958 0.0042
## class 2:  0.9394 0.0606
## class 3:  0.9919 0.0081
## class 4:  0.9948 0.0052
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9996 0.0004
## class 2:  0.9715 0.0285
## class 3:  0.9981 0.0019
## class 4:  0.9990 0.0010
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.9091 0.0856 0.0052
## class 2:  0.3162 0.4368 0.2470
## class 3:  0.7126 0.2823 0.0051
## class 4:  0.8681 0.1253 0.0066
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.9785 0.0194 0.0021
## class 2:  0.3830 0.3683 0.2487
## class 3:  0.7059 0.2863 0.0078
## class 4:  0.9673 0.0319 0.0008
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.7928 0.1867 0.0181 0.0024
## class 2:  0.1009 0.3294 0.3581 0.2116
## class 3:  0.0000 0.3529 0.5671 0.0800
## class 4:  0.0988 0.8504 0.0508 0.0000
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.8211 0.1758 0.0029 0.0002
## class 2:  0.1894 0.5311 0.2190 0.0605
## class 3:  0.2028 0.6073 0.1817 0.0082
## class 4:  0.1909 0.7789 0.0299 0.0003
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.4993 0.4028 0.0513 0.0098 0.0370
## class 2:  0.0676 0.2836 0.3354 0.2299 0.0835
## class 3:  0.0017 0.2849 0.5390 0.1649 0.0095
## class 4:  0.0385 0.7130 0.2396 0.0089 0.0000
## 
## Estimated class population shares 
##  0.2323 0.0713 0.1734 0.523 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.2058 0.0614 0.1543 0.5785 
##  
## ========================================================= 
## Fit for 4 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 91 
## residual degrees of freedom: 29832 
## maximum log-likelihood: -120317.3 
##  
## AIC(4): 240816.6
## BIC(4): 241572.5
## G^2(4): 8329.226 (Likelihood ratio/deviance statistic) 
## X^2(4): 4809166 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model5" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Model5</h2>
<pre class="r"><code>model5_b &lt;- poLCA(items_b, data_b, nclass = 5, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -119603.6 ... best llik = -119603.6
## Model 2: llik = -119603.6 ... best llik = -119603.6
## Model 3: llik = -119603.6 ... best llik = -119603.6
## Model 4: llik = -119603.6 ... best llik = -119603.6
## Model 5: llik = -119603.6 ... best llik = -119603.6
## Model 6: llik = -119603.6 ... best llik = -119603.6
## Model 7: llik = -119603.6 ... best llik = -119603.6
## Model 8: llik = -119603.6 ... best llik = -119603.6
## Model 9: llik = -119603.6 ... best llik = -119603.6
## Model 10: llik = -119603.6 ... best llik = -119603.6
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.7847 0.2153
## class 2:  0.9961 0.0039
## class 3:  0.8268 0.1732
## class 4:  0.9862 0.0138
## class 5:  0.9982 0.0018
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.7043 0.2957
## class 2:  0.9999 0.0001
## class 3:  0.9939 0.0061
## class 4:  0.9955 0.0045
## class 5:  0.9991 0.0009
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.8969 0.1031
## class 2:  0.9988 0.0012
## class 3:  0.8853 0.1147
## class 4:  0.9973 0.0027
## class 5:  0.9977 0.0023
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.6976 0.3024
## class 2:  0.9995 0.0005
## class 3:  0.9795 0.0205
## class 4:  0.9821 0.0179
## class 5:  0.9995 0.0005
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  0.9836 0.0164
## class 2:  0.9998 0.0002
## class 3:  0.9945 0.0055
## class 4:  1.0000 0.0000
## class 5:  1.0000 0.0000
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  0.9917 0.0083
## class 2:  1.0000 0.0000
## class 3:  0.9981 0.0019
## class 4:  1.0000 0.0000
## class 5:  1.0000 0.0000
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9414 0.0586
## class 2:  0.9960 0.0040
## class 3:  0.9604 0.0396
## class 4:  0.9910 0.0090
## class 5:  0.9956 0.0044
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9552 0.0448
## class 2:  0.9990 0.0010
## class 3:  0.9952 0.0048
## class 4:  0.9977 0.0023
## class 5:  0.9996 0.0004
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.4408 0.3608 0.1984
## class 2:  0.9068 0.0932 0.0000
## class 3:  0.0662 0.7274 0.2064
## class 4:  0.7735 0.2261 0.0004
## class 5:  0.9126 0.0823 0.0051
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.2667 0.3975 0.3358
## class 2:  0.9746 0.0244 0.0009
## class 3:  0.5842 0.3485 0.0673
## class 4:  0.7198 0.2695 0.0107
## class 5:  0.9787 0.0183 0.0030
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.0419 0.1305 0.4424 0.3851
## class 2:  0.0915 0.8571 0.0514 0.0000
## class 3:  0.1405 0.6671 0.1924 0.0000
## class 4:  0.0000 0.2850 0.6192 0.0958
## class 5:  0.7938 0.1867 0.0172 0.0023
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.1833 0.4536 0.2594 0.1036
## class 2:  0.1916 0.7768 0.0312 0.0004
## class 3:  0.1691 0.6976 0.1310 0.0022
## class 4:  0.2145 0.5904 0.1843 0.0108
## class 5:  0.8174 0.1797 0.0026 0.0003
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0560 0.1190 0.3035 0.3703 0.1512
## class 2:  0.0368 0.7070 0.2448 0.0114 0.0000
## class 3:  0.0607 0.5360 0.3553 0.0462 0.0018
## class 4:  0.0010 0.2716 0.5399 0.1761 0.0114
## class 5:  0.4975 0.4047 0.0510 0.0094 0.0373
## 
## Estimated class population shares 
##  0.0371 0.5063 0.0705 0.1528 0.2334 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.0316 0.5754 0.0534 0.1346 0.2049 
##  
## ========================================================= 
## Fit for 5 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 114 
## residual degrees of freedom: 29809 
## maximum log-likelihood: -119603.6 
##  
## AIC(5): 239435.2
## BIC(5): 240382.1
## G^2(5): 6968.655 (Likelihood ratio/deviance statistic) 
## X^2(5): 816786.4 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model6" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Model6</h2>
<pre class="r"><code>model6_b &lt;- poLCA(items_b, data_b, nclass = 6, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -119247.1 ... best llik = -119247.1
## Model 2: llik = -119247.1 ... best llik = -119247.1
## Model 3: llik = -119247.1 ... best llik = -119247.1
## Model 4: llik = -119352 ... best llik = -119247.1
## Model 5: llik = -119249.6 ... best llik = -119247.1
## Model 6: llik = -119351.3 ... best llik = -119247.1
## Model 7: llik = -119352 ... best llik = -119247.1
## Model 8: llik = -119352 ... best llik = -119247.1
## Model 9: llik = -119291.8 ... best llik = -119247.1
## Model 10: llik = -119288.1 ... best llik = -119247.1
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.8789 0.1211
## class 2:  0.9716 0.0284
## class 3:  0.9886 0.0114
## class 4:  0.9984 0.0016
## class 5:  0.9961 0.0039
## class 6:  0.4340 0.5660
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9933 0.0067
## class 2:  0.6583 0.3417
## class 3:  0.9963 0.0037
## class 4:  0.9993 0.0007
## class 5:  0.9999 0.0001
## class 6:  0.8638 0.1362
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9081 0.0919
## class 2:  0.9955 0.0045
## class 3:  0.9963 0.0037
## class 4:  0.9982 0.0018
## class 5:  0.9990 0.0010
## class 6:  0.7260 0.2740
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9779 0.0221
## class 2:  0.5880 0.4120
## class 3:  0.9865 0.0135
## class 4:  1.0000 0.0000
## class 5:  0.9996 0.0004
## class 6:  0.9073 0.0927
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  0.9964 0.0036
## class 2:  0.9977 0.0023
## class 3:  1.0000 0.0000
## class 4:  1.0000 0.0000
## class 5:  0.9998 0.0002
## class 6:  0.9669 0.0331
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  0.9983 0.0017
## class 2:  0.9935 0.0065
## class 3:  1.0000 0.0000
## class 4:  1.0000 0.0000
## class 5:  1.0000 0.0000
## class 6:  0.9919 0.0081
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9655 0.0345
## class 2:  0.9806 0.0194
## class 3:  0.9900 0.0100
## class 4:  0.9959 0.0041
## class 5:  0.9962 0.0038
## class 6:  0.8953 0.1047
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9972 0.0028
## class 2:  0.9599 0.0401
## class 3:  0.9971 0.0029
## class 4:  0.9996 0.0004
## class 5:  0.9990 0.0010
## class 6:  0.9641 0.0359
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.1060 0.7119 0.1821
## class 2:  0.6200 0.2620 0.1180
## class 3:  0.7429 0.2525 0.0046
## class 4:  0.9196 0.0772 0.0032
## class 5:  0.9152 0.0848 0.0000
## class 6:  0.1344 0.5479 0.3176
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.6079 0.3204 0.0717
## class 2:  0.1851 0.3750 0.4399
## class 3:  0.7162 0.2757 0.0081
## class 4:  0.9826 0.0162 0.0012
## class 5:  0.9780 0.0214 0.0006
## class 6:  0.4744 0.3957 0.1299
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.1849 0.7003 0.1148 0.0000
## class 2:  0.0656 0.1373 0.3488 0.4483
## class 3:  0.0000 0.3059 0.6021 0.0920
## class 4:  0.7946 0.1858 0.0172 0.0023
## class 5:  0.0902 0.8560 0.0537 0.0000
## class 6:  0.0265 0.2571 0.5540 0.1624
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.2164 0.7225 0.0611 0.0000
## class 2:  0.2902 0.5212 0.1091 0.0794
## class 3:  0.2048 0.5968 0.1880 0.0105
## class 4:  0.8185 0.1785 0.0028 0.0003
## class 5:  0.1916 0.7766 0.0313 0.0005
## class 6:  0.0294 0.3777 0.4959 0.0970
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0859 0.6361 0.2686 0.0095 0.0000
## class 2:  0.0871 0.1625 0.2854 0.3200 0.1450
## class 3:  0.0020 0.2661 0.5442 0.1757 0.0120
## class 4:  0.4982 0.4035 0.0512 0.0097 0.0374
## class 5:  0.0361 0.7080 0.2447 0.0113 0.0000
## class 6:  0.0000 0.0933 0.4453 0.3614 0.1000
## 
## Estimated class population shares 
##  0.0665 0.0241 0.1596 0.2312 0.4974 0.0212 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.0473 0.0203 0.137 0.2041 0.5737 0.0177 
##  
## ========================================================= 
## Fit for 6 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 137 
## residual degrees of freedom: 29786 
## maximum log-likelihood: -119247.1 
##  
## AIC(6): 238768.2
## BIC(6): 239906.2
## G^2(6): 6337.08 (Likelihood ratio/deviance statistic) 
## X^2(6): 3937301 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model7" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> Model7</h2>
<pre class="r"><code>model7_b &lt;- poLCA(items_b, data_b, nclass = 7, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -119091 ... best llik = -119091
## Model 2: llik = -119040.9 ... best llik = -119040.9
## Model 3: llik = -119033.8 ... best llik = -119033.8
## Model 4: llik = -119013.1 ... best llik = -119013.1
## Model 5: llik = -119091 ... best llik = -119013.1
## Model 6: llik = -119052 ... best llik = -119013.1
## Model 7: llik = -119082.2 ... best llik = -119013.1
## Model 8: llik = -119130.3 ... best llik = -119013.1
## Model 9: llik = -119033.8 ... best llik = -119013.1
## Model 10: llik = -119065.3 ... best llik = -119013.1
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9916 0.0084
## class 2:  0.9770 0.0230
## class 3:  0.8300 0.1700
## class 4:  0.9805 0.0195
## class 5:  0.9973 0.0027
## class 6:  0.9987 0.0013
## class 7:  0.4451 0.5549
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9816 0.0184
## class 2:  0.6772 0.3228
## class 3:  0.9910 0.0090
## class 4:  0.9992 0.0008
## class 5:  0.9998 0.0002
## class 6:  0.9993 0.0007
## class 7:  0.8568 0.1432
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9983 0.0017
## class 2:  0.9955 0.0045
## class 3:  0.8641 0.1359
## class 4:  0.9951 0.0049
## class 5:  0.9992 0.0008
## class 6:  0.9988 0.0012
## class 7:  0.7273 0.2727
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9522 0.0478
## class 2:  0.6237 0.3763
## class 3:  0.9751 0.0249
## class 4:  0.9960 0.0040
## class 5:  0.9993 0.0007
## class 6:  1.0000 0.0000
## class 7:  0.8989 0.1011
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9974 0.0026
## class 3:  0.9942 0.0058
## class 4:  0.9996 0.0004
## class 5:  0.9999 0.0001
## class 6:  1.0000 0.0000
## class 7:  0.9682 0.0318
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  0.9992 0.0008
## class 2:  0.9933 0.0067
## class 3:  0.9986 0.0014
## class 4:  1.0000 0.0000
## class 5:  1.0000 0.0000
## class 6:  1.0000 0.0000
## class 7:  0.9917 0.0083
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9913 0.0087
## class 2:  0.9779 0.0221
## class 3:  0.9530 0.0470
## class 4:  0.9901 0.0099
## class 5:  0.9963 0.0037
## class 6:  0.9962 0.0038
## class 7:  0.8974 0.1026
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9955 0.0045
## class 2:  0.9579 0.0421
## class 3:  0.9966 0.0034
## class 4:  0.9981 0.0019
## class 5:  0.9990 0.0010
## class 6:  0.9996 0.0004
## class 7:  0.9653 0.0347
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.5294 0.4586 0.0120
## class 2:  0.6686 0.2269 0.1045
## class 3:  0.1126 0.6291 0.2583
## class 4:  0.8076 0.1849 0.0075
## class 5:  0.8997 0.1003 0.0000
## class 6:  0.9213 0.0765 0.0023
## class 7:  0.1165 0.5720 0.3115
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.0001 0.9646 0.0353
## class 2:  0.2406 0.3424 0.4170
## class 3:  0.6741 0.2208 0.1051
## class 4:  1.0000 0.0000 0.0000
## class 5:  0.9806 0.0189 0.0005
## class 6:  0.9823 0.0168 0.0009
## class 7:  0.4444 0.4149 0.1407
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.0000 0.3921 0.5518 0.0561
## class 2:  0.0612 0.1001 0.3164 0.5223
## class 3:  0.2650 0.6512 0.0837 0.0000
## class 4:  0.0089 0.4583 0.4642 0.0686
## class 5:  0.0963 0.8472 0.0565 0.0000
## class 6:  0.7981 0.1803 0.0187 0.0029
## class 7:  0.0193 0.2379 0.5781 0.1648
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.2392 0.6481 0.1111 0.0016
## class 2:  0.2670 0.5126 0.1294 0.0909
## class 3:  0.2417 0.6985 0.0599 0.0000
## class 4:  0.1714 0.6159 0.2020 0.0107
## class 5:  0.1985 0.7787 0.0227 0.0001
## class 6:  0.8228 0.1736 0.0033 0.0003
## class 7:  0.0289 0.3799 0.4924 0.0987
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0136 0.3717 0.4953 0.1165 0.0030
## class 2:  0.0813 0.1284 0.2601 0.3626 0.1676
## class 3:  0.1150 0.6567 0.2187 0.0097 0.0000
## class 4:  0.0000 0.2411 0.5741 0.1747 0.0102
## class 5:  0.0399 0.7397 0.2189 0.0016 0.0000
## class 6:  0.5015 0.3973 0.0525 0.0111 0.0375
## class 7:  0.0000 0.0891 0.4481 0.3619 0.1009
## 
## Estimated class population shares 
##  0.0596 0.0232 0.0461 0.1447 0.4779 0.2277 0.0209 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.0648 0.0199 0.0295 0.1041 0.56 0.2036 0.0181 
##  
## ========================================================= 
## Fit for 7 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 160 
## residual degrees of freedom: 29763 
## maximum log-likelihood: -119013.1 
##  
## AIC(7): 238346.3
## BIC(7): 239675.3
## G^2(7): 5906.466 (Likelihood ratio/deviance statistic) 
## X^2(7): 3430615 (Chi-square goodness of fit) 
##  
## ALERT: iterations finished, MAXIMUM LIKELIHOOD NOT FOUND 
## </code></pre>
</div>
<div id="model8" class="section level2" number="1.8">
<h2><span class="header-section-number">1.8</span> Model8</h2>
<pre class="r"><code>model8_b &lt;- poLCA(items_b, data_b, nclass = 8, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -118821.5 ... best llik = -118821.5
## Model 2: llik = -118872.8 ... best llik = -118821.5
## Model 3: llik = -118915.7 ... best llik = -118821.5
## Model 4: llik = -118914.9 ... best llik = -118821.5
## Model 5: llik = -118828.1 ... best llik = -118821.5
## Model 6: llik = -118856.7 ... best llik = -118821.5
## Model 7: llik = -118821.5 ... best llik = -118821.5
## Model 8: llik = -118856.7 ... best llik = -118821.5
## Model 9: llik = -118897.9 ... best llik = -118821.5
## Model 10: llik = -118854.8 ... best llik = -118821.5
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9984 0.0016
## class 2:  0.9820 0.0180
## class 3:  0.9913 0.0087
## class 4:  0.9977 0.0023
## class 5:  0.9821 0.0179
## class 6:  0.8228 0.1772
## class 7:  0.4319 0.5681
## class 8:  0.9566 0.0434
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9993 0.0007
## class 2:  0.7214 0.2786
## class 3:  0.9800 0.0200
## class 4:  0.9998 0.0002
## class 5:  0.9990 0.0010
## class 6:  0.9962 0.0038
## class 7:  0.8443 0.1557
## class 8:  0.8273 0.1727
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9982 0.0018
## class 2:  0.9961 0.0039
## class 3:  0.9982 0.0018
## class 4:  0.9994 0.0006
## class 5:  0.9956 0.0044
## class 6:  0.8691 0.1309
## class 7:  0.7159 0.2841
## class 8:  0.9809 0.0191
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.6726 0.3274
## class 3:  0.9506 0.0494
## class 4:  0.9995 0.0005
## class 5:  0.9960 0.0040
## class 6:  0.9866 0.0134
## class 7:  0.8901 0.1099
## class 8:  0.7768 0.2232
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9964 0.0036
## class 3:  1.0000 0.0000
## class 4:  0.9999 0.0001
## class 5:  0.9997 0.0003
## class 6:  0.9938 0.0062
## class 7:  0.9673 0.0327
## class 8:  1.0000 0.0000
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9967 0.0033
## class 3:  0.9993 0.0007
## class 4:  1.0000 0.0000
## class 5:  1.0000 0.0000
## class 6:  0.9989 0.0011
## class 7:  0.9904 0.0096
## class 8:  0.9925 0.0075
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9959 0.0041
## class 2:  0.9706 0.0294
## class 3:  0.9908 0.0092
## class 4:  0.9965 0.0035
## class 5:  0.9905 0.0095
## class 6:  0.9509 0.0491
## class 7:  0.8976 0.1024
## class 8:  0.9980 0.0020
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9996 0.0004
## class 2:  0.9568 0.0432
## class 3:  0.9950 0.0050
## class 4:  0.9990 0.0010
## class 5:  0.9982 0.0018
## class 6:  0.9955 0.0045
## class 7:  0.9625 0.0375
## class 8:  0.9933 0.0067
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.9165 0.0802 0.0032
## class 2:  0.6721 0.2520 0.0759
## class 3:  0.5355 0.4542 0.0104
## class 4:  0.9103 0.0897 0.0000
## class 5:  0.8198 0.1716 0.0086
## class 6:  0.1082 0.7448 0.1470
## class 7:  0.1161 0.5587 0.3252
## class 8:  0.3670 0.1535 0.4795
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.9819 0.0178 0.0003
## class 2:  0.2403 0.3990 0.3608
## class 3:  0.0589 0.9072 0.0338
## class 4:  0.9816 0.0184 0.0000
## class 5:  1.0000 0.0000 0.0000
## class 6:  0.7806 0.2194 0.0000
## class 7:  0.4275 0.4191 0.1534
## class 8:  0.1698 0.1847 0.6456
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.7974 0.1811 0.0186 0.0029
## class 2:  0.0089 0.0052 0.3364 0.6495
## class 3:  0.0000 0.3850 0.5645 0.0505
## class 4:  0.0958 0.8487 0.0555 0.0000
## class 5:  0.0060 0.4485 0.4753 0.0701
## class 6:  0.2036 0.7137 0.0827 0.0000
## class 7:  0.0234 0.2216 0.5887 0.1663
## class 8:  0.3076 0.5176 0.1669 0.0079
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.8216 0.1746 0.0034 0.0003
## class 2:  0.2168 0.5199 0.1592 0.1041
## class 3:  0.2440 0.6430 0.1114 0.0017
## class 4:  0.1991 0.7782 0.0226 0.0001
## class 5:  0.1737 0.6101 0.2046 0.0116
## class 6:  0.1669 0.7493 0.0822 0.0015
## class 7:  0.0319 0.3682 0.4977 0.1022
## class 8:  0.4148 0.5618 0.0234 0.0000
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.5001 0.3985 0.0527 0.0112 0.0376
## class 2:  0.0584 0.0452 0.2422 0.4567 0.1975
## class 3:  0.0143 0.3719 0.5007 0.1111 0.0019
## class 4:  0.0398 0.7371 0.2202 0.0029 0.0000
## class 5:  0.0000 0.2422 0.5734 0.1743 0.0102
## class 6:  0.0751 0.6471 0.2614 0.0165 0.0000
## class 7:  0.0000 0.0852 0.4377 0.3735 0.1036
## class 8:  0.1777 0.5486 0.2467 0.0131 0.0138
## 
## Estimated class population shares 
##  0.2293 0.0196 0.0613 0.4727 0.1377 0.0479 0.0194 0.0121 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.2043 0.0175 0.0641 0.5564 0.104 0.0276 0.0167 0.0094 
##  
## ========================================================= 
## Fit for 8 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 183 
## residual degrees of freedom: 29740 
## maximum log-likelihood: -118821.5 
##  
## AIC(8): 238009
## BIC(8): 239529
## G^2(8): 5552.539 (Likelihood ratio/deviance statistic) 
## X^2(8): 2325093 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model9" class="section level2" number="1.9">
<h2><span class="header-section-number">1.9</span> Model9</h2>
<pre class="r"><code>model9_b &lt;- poLCA(items_b, data_b, nclass = 9, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -118735.7 ... best llik = -118735.7
## Model 2: llik = -118768.5 ... best llik = -118735.7
## Model 3: llik = -118726.9 ... best llik = -118726.9
## Model 4: llik = -118759.4 ... best llik = -118726.9
## Model 5: llik = -118682.7 ... best llik = -118682.7
## Model 6: llik = -118671.8 ... best llik = -118671.8
## Model 7: llik = -118682.7 ... best llik = -118671.8
## Model 8: llik = -118771.1 ... best llik = -118671.8
## Model 9: llik = -118771.6 ... best llik = -118671.8
## Model 10: llik = -118685.7 ... best llik = -118671.8
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##            Pr(1)  Pr(2)
## class 1:  0.9843 0.0157
## class 2:  0.6628 0.3372
## class 3:  0.9918 0.0082
## class 4:  0.5052 0.4948
## class 5:  1.0000 0.0000
## class 6:  0.9882 0.0118
## class 7:  0.9972 0.0028
## class 8:  0.9983 0.0017
## class 9:  0.9462 0.0538
## 
## $bul_s
##            Pr(1)  Pr(2)
## class 1:  0.9974 0.0026
## class 2:  1.0000 0.0000
## class 3:  0.9840 0.0160
## class 4:  0.8257 0.1743
## class 5:  1.0000 0.0000
## class 6:  0.6564 0.3436
## class 7:  0.9998 0.0002
## class 8:  0.9993 0.0007
## class 9:  0.8500 0.1500
## 
## $int_c
##            Pr(1)  Pr(2)
## class 1:  0.9953 0.0047
## class 2:  0.7743 0.2257
## class 3:  1.0000 0.0000
## class 4:  0.7591 0.2409
## class 5:  1.0000 0.0000
## class 6:  0.9955 0.0045
## class 7:  0.9992 0.0008
## class 8:  0.9977 0.0023
## class 9:  0.9683 0.0317
## 
## $int_s
##            Pr(1)  Pr(2)
## class 1:  0.9935 0.0065
## class 2:  0.9877 0.0123
## class 3:  0.9557 0.0443
## class 4:  0.8714 0.1286
## class 5:  1.0000 0.0000
## class 6:  0.5828 0.4172
## class 7:  0.9994 0.0006
## class 8:  1.0000 0.0000
## class 9:  0.8099 0.1901
## 
## $vio_c
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9889 0.0111
## class 3:  1.0000 0.0000
## class 4:  0.9645 0.0355
## class 5:  1.0000 0.0000
## class 6:  1.0000 0.0000
## class 7:  0.9999 0.0001
## class 8:  1.0000 0.0000
## class 9:  1.0000 0.0000
## 
## $vio_s
##            Pr(1)  Pr(2)
## class 1:  1.0000 0.0000
## class 2:  0.9981 0.0019
## class 3:  1.0000 0.0000
## class 4:  0.9899 0.0101
## class 5:  1.0000 0.0000
## class 6:  0.9970 0.0030
## class 7:  1.0000 0.0000
## class 8:  1.0000 0.0000
## class 9:  0.9889 0.0111
## 
## $sex_c
##            Pr(1)  Pr(2)
## class 1:  0.9899 0.0101
## class 2:  0.9254 0.0746
## class 3:  0.9897 0.0103
## class 4:  0.9025 0.0975
## class 5:  0.9889 0.0111
## class 6:  0.9759 0.0241
## class 7:  0.9961 0.0039
## class 8:  0.9957 0.0043
## class 9:  0.9976 0.0024
## 
## $sex_s
##            Pr(1)  Pr(2)
## class 1:  0.9979 0.0021
## class 2:  0.9919 0.0081
## class 3:  0.9951 0.0049
## class 4:  0.9618 0.0382
## class 5:  0.9828 0.0172
## class 6:  0.9533 0.0467
## class 7:  0.9991 0.0009
## class 8:  0.9996 0.0004
## class 9:  0.9958 0.0042
## 
## $conflict_col
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.7925 0.1983 0.0093
## class 2:  0.1306 0.6795 0.1898
## class 3:  0.4769 0.5071 0.0161
## class 4:  0.1133 0.5891 0.2976
## class 5:  0.8078 0.1509 0.0413
## class 6:  0.6556 0.2791 0.0653
## class 7:  0.8915 0.1059 0.0025
## class 8:  0.9129 0.0838 0.0034
## class 9:  0.3393 0.1562 0.5045
## 
## $conflict_leid
##            Pr(1)  Pr(2)  Pr(3)
## class 1:  0.8383 0.1566 0.0051
## class 2:  0.8730 0.1261 0.0009
## class 3:  0.1233 0.8591 0.0176
## class 4:  0.3228 0.5040 0.1732
## class 5:  0.8484 0.1233 0.0283
## class 6:  0.1112 0.4432 0.4456
## class 7:  0.9976 0.0024 0.0000
## class 8:  0.9824 0.0174 0.0002
## class 9:  0.1888 0.2135 0.5977
## 
## $steunleid_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.0000 0.3164 0.5881 0.0955
## class 2:  0.1862 0.6894 0.1196 0.0048
## class 3:  0.0302 0.5789 0.3784 0.0125
## class 4:  0.0111 0.1481 0.6369 0.2039
## class 5:  0.0000 0.0218 0.0000 0.9782
## class 6:  0.0030 0.0384 0.4026 0.5559
## class 7:  0.0933 0.8397 0.0665 0.0004
## class 8:  0.7972 0.1848 0.0180 0.0000
## class 9:  0.3324 0.5003 0.1573 0.0100
## 
## $steuncol_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:  0.1722 0.5939 0.2261 0.0077
## class 2:  0.1290 0.7006 0.1646 0.0058
## class 3:  0.2675 0.6806 0.0502 0.0016
## class 4:  0.0268 0.3532 0.4963 0.1237
## class 5:  0.3191 0.0768 0.1427 0.4613
## class 6:  0.2543 0.6010 0.1240 0.0207
## class 7:  0.1952 0.7740 0.0303 0.0006
## class 8:  0.8192 0.1780 0.0027 0.0000
## class 9:  0.4154 0.5569 0.0277 0.0000
## 
## $psyveil_RR
##            Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:  0.0000 0.1661 0.6067 0.2139 0.0134
## class 2:  0.0534 0.5463 0.3448 0.0515 0.0041
## class 3:  0.0385 0.5666 0.3614 0.0335 0.0000
## class 4:  0.0035 0.0619 0.4159 0.3977 0.1210
## class 5:  0.2629 0.4467 0.0262 0.0609 0.2033
## class 6:  0.0068 0.0449 0.3247 0.4664 0.1571
## class 7:  0.0365 0.7137 0.2403 0.0095 0.0000
## class 8:  0.5006 0.4009 0.0510 0.0100 0.0374
## class 9:  0.1887 0.5684 0.2204 0.0080 0.0145
## 
## Estimated class population shares 
##  0.1201 0.0314 0.0572 0.0186 0.0039 0.0167 0.5094 0.2301 0.0126 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.1133 0.0216 0.0562 0.0163 0.0038 0.016 0.5582 0.204 0.0106 
##  
## ========================================================= 
## Fit for 9 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 206 
## residual degrees of freedom: 29717 
## maximum log-likelihood: -118671.8 
##  
## AIC(9): 237755.6
## BIC(9): 239466.7
## G^2(9): 5270.551 (Likelihood ratio/deviance statistic) 
## X^2(9): 1701141 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model10" class="section level2" number="1.10">
<h2><span class="header-section-number">1.10</span> Model10</h2>
<pre class="r"><code>model10_b &lt;- poLCA(items_b, data_b, nclass = 10, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -118641.5 ... best llik = -118641.5
## Model 2: llik = -118597.7 ... best llik = -118597.7
## Model 3: llik = -118603.1 ... best llik = -118597.7
## Model 4: llik = -118538.2 ... best llik = -118538.2
## Model 5: llik = -118700.1 ... best llik = -118538.2
## Model 6: llik = -118582.8 ... best llik = -118538.2
## Model 7: llik = -118551.9 ... best llik = -118538.2
## Model 8: llik = -118545.9 ... best llik = -118538.2
## Model 9: llik = -118641.3 ... best llik = -118538.2
## Model 10: llik = -118586.1 ... best llik = -118538.2
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##             Pr(1)  Pr(2)
## class 1:   0.9516 0.0484
## class 2:   0.9924 0.0076
## class 3:   0.9985 0.0015
## class 4:   0.3684 0.6316
## class 5:   0.9847 0.0153
## class 6:   1.0000 0.0000
## class 7:   0.9971 0.0029
## class 8:   0.9962 0.0038
## class 9:   0.6490 0.3510
## class 10:  0.9161 0.0839
## 
## $bul_s
##             Pr(1)  Pr(2)
## class 1:   0.8636 0.1364
## class 2:   0.9803 0.0197
## class 3:   0.9992 0.0008
## class 4:   0.7580 0.2420
## class 5:   0.9978 0.0022
## class 6:   1.0000 0.0000
## class 7:   1.0000 0.0000
## class 8:   0.6735 0.3265
## class 9:   1.0000 0.0000
## class 10:  0.9968 0.0032
## 
## $int_c
##             Pr(1)  Pr(2)
## class 1:   0.9727 0.0273
## class 2:   1.0000 0.0000
## class 3:   0.9981 0.0019
## class 4:   0.6863 0.3137
## class 5:   0.9955 0.0045
## class 6:   1.0000 0.0000
## class 7:   0.9992 0.0008
## class 8:   0.9947 0.0053
## class 9:   0.7457 0.2543
## class 10:  0.9690 0.0310
## 
## $int_s
##             Pr(1)  Pr(2)
## class 1:   0.8263 0.1737
## class 2:   0.9523 0.0477
## class 3:   1.0000 0.0000
## class 4:   0.8210 0.1790
## class 5:   0.9933 0.0067
## class 6:   1.0000 0.0000
## class 7:   1.0000 0.0000
## class 8:   0.5990 0.4010
## class 9:   0.9875 0.0125
## class 10:  0.9950 0.0050
## 
## $vio_c
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   1.0000 0.0000
## class 3:   1.0000 0.0000
## class 4:   0.9485 0.0515
## class 5:   1.0000 0.0000
## class 6:   1.0000 0.0000
## class 7:   0.9998 0.0002
## class 8:   1.0000 0.0000
## class 9:   0.9869 0.0131
## class 10:  1.0000 0.0000
## 
## $vio_s
##             Pr(1)  Pr(2)
## class 1:   0.9920 0.0080
## class 2:   0.9981 0.0019
## class 3:   1.0000 0.0000
## class 4:   0.9842 0.0158
## class 5:   1.0000 0.0000
## class 6:   1.0000 0.0000
## class 7:   1.0000 0.0000
## class 8:   0.9979 0.0021
## class 9:   1.0000 0.0000
## class 10:  1.0000 0.0000
## 
## $sex_c
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   0.9859 0.0141
## class 3:   0.9959 0.0041
## class 4:   0.8718 0.1282
## class 5:   0.9906 0.0094
## class 6:   0.9890 0.0110
## class 7:   0.9963 0.0037
## class 8:   0.9750 0.0250
## class 9:   0.9165 0.0835
## class 10:  0.9875 0.0125
## 
## $sex_s
##             Pr(1)  Pr(2)
## class 1:   0.9963 0.0037
## class 2:   0.9940 0.0060
## class 3:   0.9996 0.0004
## class 4:   0.9476 0.0524
## class 5:   0.9979 0.0021
## class 6:   0.9837 0.0163
## class 7:   0.9992 0.0008
## class 8:   0.9549 0.0451
## class 9:   0.9913 0.0087
## class 10:  0.9988 0.0012
## 
## $conflict_col
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.3141 0.1361 0.5499
## class 2:   0.5399 0.4482 0.0119
## class 3:   0.9143 0.0823 0.0034
## class 4:   0.1391 0.5037 0.3572
## class 5:   0.9487 0.0513 0.0000
## class 6:   0.7561 0.2007 0.0432
## class 7:   0.8940 0.1032 0.0028
## class 8:   0.6460 0.2850 0.0690
## class 9:   0.1405 0.6538 0.2057
## class 10:  0.0000 0.9222 0.0778
## 
## $conflict_leid
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.1409 0.2016 0.6575
## class 2:   0.3137 0.6724 0.0140
## class 3:   0.9844 0.0154 0.0002
## class 4:   0.3461 0.4451 0.2088
## class 5:   0.8403 0.1556 0.0041
## class 6:   0.8454 0.1271 0.0275
## class 7:   1.0000 0.0000 0.0000
## class 8:   0.1138 0.4579 0.4283
## class 9:   0.8946 0.1040 0.0014
## class 10:  0.5206 0.4626 0.0169
## 
## $steunleid_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.3419 0.4849 0.1624 0.0109
## class 2:   0.0493 0.6276 0.3158 0.0073
## class 3:   0.7991 0.1840 0.0169 0.0000
## class 4:   0.0138 0.1527 0.5872 0.2463
## class 5:   0.0016 0.3286 0.5808 0.0890
## class 6:   0.0000 0.0210 0.0000 0.9790
## class 7:   0.0957 0.8497 0.0545 0.0000
## class 8:   0.0070 0.0508 0.4280 0.5142
## class 9:   0.2230 0.6763 0.0965 0.0042
## class 10:  0.0045 0.3949 0.5431 0.0575
## 
## $steuncol_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.4124 0.5576 0.0300 0.0000
## class 2:   0.3272 0.6533 0.0182 0.0014
## class 3:   0.8208 0.1764 0.0028 0.0000
## class 4:   0.0358 0.3378 0.4650 0.1614
## class 5:   0.1988 0.5995 0.1943 0.0074
## class 6:   0.2945 0.0935 0.1673 0.4447
## class 7:   0.1899 0.7793 0.0303 0.0005
## class 8:   0.2534 0.5893 0.1363 0.0210
## class 9:   0.1577 0.6956 0.1404 0.0063
## class 10:  0.0344 0.6318 0.3252 0.0086
## 
## $psyveil_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:   0.1974 0.5572 0.2215 0.0076 0.0164
## class 2:   0.0516 0.6878 0.2606 0.0000 0.0000
## class 3:   0.5014 0.3996 0.0515 0.0101 0.0374
## class 4:   0.0060 0.0723 0.3635 0.3997 0.1585
## class 5:   0.0000 0.2004 0.5892 0.1972 0.0131
## class 6:   0.2506 0.4171 0.0378 0.0866 0.2079
## class 7:   0.0373 0.7168 0.2372 0.0088 0.0000
## class 8:   0.0058 0.0442 0.3435 0.4567 0.1498
## class 9:   0.0645 0.5913 0.2944 0.0440 0.0058
## class 10:  0.0023 0.1414 0.6379 0.2141 0.0043
## 
## Estimated class population shares 
##  0.0111 0.0591 0.2289 0.0128 0.1144 0.0041 0.4894 0.0184 0.0263 0.0354 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.0106 0.0451 0.2048 0.011 0.0941 0.0033 0.5564 0.0178 0.018 0.039 
##  
## ========================================================= 
## Fit for 10 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 229 
## residual degrees of freedom: 29694 
## maximum log-likelihood: -118538.2 
##  
## AIC(10): 237534.4
## BIC(10): 239436.5
## G^2(10): 5025.807 (Likelihood ratio/deviance statistic) 
## X^2(10): 453010.7 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model11" class="section level2" number="1.11">
<h2><span class="header-section-number">1.11</span> Model11</h2>
<pre class="r"><code>model11_b &lt;- poLCA(items_b, data_b, nclass = 11, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -118449.9 ... best llik = -118449.9
## Model 2: llik = -118483 ... best llik = -118449.9
## Model 3: llik = -118472.9 ... best llik = -118449.9
## Model 4: llik = -118561.8 ... best llik = -118449.9
## Model 5: llik = -118528.3 ... best llik = -118449.9
## Model 6: llik = -118476.2 ... best llik = -118449.9
## Model 7: llik = -118479.3 ... best llik = -118449.9
## Model 8: llik = -118475.9 ... best llik = -118449.9
## Model 9: llik = -118529.2 ... best llik = -118449.9
## Model 10: llik = -118476 ... best llik = -118449.9
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##             Pr(1)  Pr(2)
## class 1:   0.9983 0.0017
## class 2:   0.9566 0.0434
## class 3:   0.9707 0.0293
## class 4:   0.3801 0.6199
## class 5:   1.0000 0.0000
## class 6:   1.0000 0.0000
## class 7:   0.9477 0.0523
## class 8:   1.0000 0.0000
## class 9:   0.9975 0.0025
## class 10:  0.6527 0.3473
## class 11:  0.9802 0.0198
## 
## $bul_s
##             Pr(1)  Pr(2)
## class 1:   0.9992 0.0008
## class 2:   0.8938 0.1062
## class 3:   1.0000 0.0000
## class 4:   0.8114 0.1886
## class 5:   0.9984 0.0016
## class 6:   1.0000 0.0000
## class 7:   0.3116 0.6884
## class 8:   0.9336 0.0664
## class 9:   0.9998 0.0002
## class 10:  1.0000 0.0000
## class 11:  0.9800 0.0200
## 
## $int_c
##             Pr(1)  Pr(2)
## class 1:   0.9980 0.0020
## class 2:   0.9768 0.0232
## class 3:   0.9970 0.0030
## class 4:   0.6980 0.3020
## class 5:   0.9965 0.0035
## class 6:   1.0000 0.0000
## class 7:   0.9970 0.0030
## class 8:   0.9889 0.0111
## class 9:   0.9991 0.0009
## class 10:  0.7481 0.2519
## class 11:  0.9956 0.0044
## 
## $int_s
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   0.8502 0.1498
## class 3:   0.9987 0.0013
## class 4:   0.8692 0.1308
## class 5:   0.9901 0.0099
## class 6:   1.0000 0.0000
## class 7:   0.2613 0.7387
## class 8:   0.8979 0.1021
## class 9:   0.9995 0.0005
## class 10:  0.9871 0.0129
## class 11:  0.9538 0.0462
## 
## $vio_c
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   1.0000 0.0000
## class 3:   0.9991 0.0009
## class 4:   0.9552 0.0448
## class 5:   1.0000 0.0000
## class 6:   1.0000 0.0000
## class 7:   1.0000 0.0000
## class 8:   1.0000 0.0000
## class 9:   1.0000 0.0000
## class 10:  0.9880 0.0120
## class 11:  1.0000 0.0000
## 
## $vio_s
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   0.9935 0.0065
## class 3:   1.0000 0.0000
## class 4:   0.9881 0.0119
## class 5:   1.0000 0.0000
## class 6:   1.0000 0.0000
## class 7:   0.9902 0.0098
## class 8:   1.0000 0.0000
## class 9:   1.0000 0.0000
## class 10:  1.0000 0.0000
## class 11:  0.9979 0.0021
## 
## $sex_c
##             Pr(1)  Pr(2)
## class 1:   0.9958 0.0042
## class 2:   0.9982 0.0018
## class 3:   0.9898 0.0102
## class 4:   0.8862 0.1138
## class 5:   0.9946 0.0054
## class 6:   0.9847 0.0153
## class 7:   0.9842 0.0158
## class 8:   0.9741 0.0259
## class 9:   0.9961 0.0039
## class 10:  0.9200 0.0800
## class 11:  0.9888 0.0112
## 
## $sex_s
##             Pr(1)  Pr(2)
## class 1:   0.9996 0.0004
## class 2:   0.9963 0.0037
## class 3:   0.9975 0.0025
## class 4:   0.9546 0.0454
## class 5:   1.0000 0.0000
## class 6:   0.9776 0.0224
## class 7:   0.9217 0.0783
## class 8:   0.9888 0.0112
## class 9:   0.9990 0.0010
## class 10:  0.9930 0.0070
## class 11:  0.9944 0.0056
## 
## $conflict_col
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.9133 0.0835 0.0032
## class 2:   0.2966 0.1613 0.5422
## class 3:   0.7918 0.1945 0.0137
## class 4:   0.1172 0.5410 0.3418
## class 5:   0.9067 0.0933 0.0000
## class 6:   0.7662 0.1751 0.0587
## class 7:   0.6608 0.2530 0.0862
## class 8:   0.5771 0.3821 0.0409
## class 9:   0.8919 0.1052 0.0028
## class 10:  0.1149 0.6886 0.1966
## class 11:  0.3846 0.5951 0.0203
## 
## $conflict_leid
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.9821 0.0178 0.0001
## class 2:   0.1606 0.2375 0.6019
## class 3:   0.9732 0.0268 0.0000
## class 4:   0.3663 0.4636 0.1701
## class 5:   0.8007 0.1849 0.0144
## class 6:   0.8165 0.1259 0.0576
## class 7:   0.1002 0.2452 0.6545
## class 8:   0.2579 0.6060 0.1361
## class 9:   0.9903 0.0097 0.0000
## class 10:  0.8916 0.1066 0.0018
## class 11:  0.1731 0.8143 0.0127
## 
## $steunleid_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.8010 0.1851 0.0140 0.0000
## class 2:   0.3616 0.4775 0.1482 0.0126
## class 3:   0.0000 0.4822 0.4686 0.0492
## class 4:   0.0128 0.1713 0.6147 0.2012
## class 5:   0.0000 0.2573 0.6677 0.0750
## class 6:   0.0000 0.0144 0.0000 0.9856
## class 7:   0.0000 0.1506 0.2636 0.5858
## class 8:   0.0090 0.0000 0.6570 0.3340
## class 9:   0.1033 0.8651 0.0316 0.0000
## class 10:  0.2159 0.6592 0.1194 0.0055
## class 11:  0.0245 0.6244 0.3471 0.0040
## 
## $steuncol_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.8238 0.1729 0.0033 0.0000
## class 2:   0.4301 0.5437 0.0262 0.0000
## class 3:   0.0000 0.6864 0.3028 0.0109
## class 4:   0.0334 0.3368 0.4905 0.1392
## class 5:   0.5256 0.4744 0.0000 0.0000
## class 6:   0.2111 0.0867 0.1844 0.5178
## class 7:   0.2275 0.6176 0.1325 0.0224
## class 8:   0.1686 0.5963 0.2188 0.0163
## class 9:   0.1939 0.7814 0.0243 0.0004
## class 10:  0.1596 0.6996 0.1364 0.0045
## class 11:  0.1938 0.7142 0.0901 0.0019
## 
## $psyveil_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:   0.5041 0.3932 0.0534 0.0113 0.0379
## class 2:   0.2070 0.5552 0.2079 0.0112 0.0188
## class 3:   0.0000 0.2021 0.6075 0.1775 0.0129
## class 4:   0.0038 0.0736 0.4059 0.3887 0.1280
## class 5:   0.0000 0.4876 0.4287 0.0837 0.0000
## class 6:   0.2902 0.3476 0.0331 0.0731 0.2560
## class 7:   0.0167 0.1210 0.2767 0.3703 0.2153
## class 8:   0.0000 0.0000 0.4898 0.4470 0.0632
## class 9:   0.0405 0.7270 0.2251 0.0074 0.0000
## class 10:  0.0623 0.5745 0.3130 0.0482 0.0020
## class 11:  0.0392 0.5200 0.4008 0.0400 0.0000
## 
## Estimated class population shares 
##  0.2274 0.0118 0.0911 0.0149 0.0621 0.0036 0.0074 0.0269 0.4744 0.0272 0.0532 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.2049 0.0094 0.0847 0.0129 0.032 0.0029 0.0066 0.0242 0.5447 0.0186 0.0592 
##  
## ========================================================= 
## Fit for 11 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 252 
## residual degrees of freedom: 29671 
## maximum log-likelihood: -118449.9 
##  
## AIC(11): 237403.8
## BIC(11): 239497
## G^2(11): 4860.625 (Likelihood ratio/deviance statistic) 
## X^2(11): 730332.6 (Chi-square goodness of fit) 
## </code></pre>
</div>
<div id="model12" class="section level2" number="1.12">
<h2><span class="header-section-number">1.12</span> Model12</h2>
<pre class="r"><code>model12_b &lt;- poLCA(items_b, data_b, nclass = 12, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)</code></pre>
<pre><code>## Model 1: llik = -118399.4 ... best llik = -118399.4
## Model 2: llik = -118366.1 ... best llik = -118366.1
## Model 3: llik = -118371 ... best llik = -118366.1
## Model 4: llik = -118404.7 ... best llik = -118366.1
## Model 5: llik = -118402.4 ... best llik = -118366.1
## Model 6: llik = -118413.5 ... best llik = -118366.1
## Model 7: llik = -118377.4 ... best llik = -118366.1
## Model 8: llik = -118379.2 ... best llik = -118366.1
## Model 9: llik = -118354 ... best llik = -118354
## Model 10: llik = -118355.6 ... best llik = -118354
## Conditional item response (column) probabilities,
##  by outcome variable, for each class (row) 
##  
## $bul_c
##             Pr(1)  Pr(2)
## class 1:   0.9729 0.0271
## class 2:   0.9609 0.0391
## class 3:   0.9172 0.0828
## class 4:   0.9854 0.0146
## class 5:   1.0000 0.0000
## class 6:   0.4087 0.5913
## class 7:   1.0000 0.0000
## class 8:   0.9666 0.0334
## class 9:   0.5420 0.4580
## class 10:  0.9991 0.0009
## class 11:  1.0000 0.0000
## class 12:  0.9973 0.0027
## 
## $bul_s
##             Pr(1)  Pr(2)
## class 1:   0.9818 0.0182
## class 2:   0.9360 0.0640
## class 3:   0.9839 0.0161
## class 4:   1.0000 0.0000
## class 5:   1.0000 0.0000
## class 6:   0.7646 0.2354
## class 7:   0.9248 0.0752
## class 8:   0.2543 0.7457
## class 9:   1.0000 0.0000
## class 10:  0.9993 0.0007
## class 11:  0.9945 0.0055
## class 12:  0.9999 0.0001
## 
## $int_c
##             Pr(1)  Pr(2)
## class 1:   0.9918 0.0082
## class 2:   0.9814 0.0186
## class 3:   0.8848 0.1152
## class 4:   0.9967 0.0033
## class 5:   1.0000 0.0000
## class 6:   0.7059 0.2941
## class 7:   0.9909 0.0091
## class 8:   1.0000 0.0000
## class 9:   0.7711 0.2289
## class 10:  0.9998 0.0002
## class 11:  0.9977 0.0023
## class 12:  0.9991 0.0009
## 
## $int_s
##             Pr(1)  Pr(2)
## class 1:   0.9581 0.0419
## class 2:   0.9102 0.0898
## class 3:   0.9640 0.0360
## class 4:   0.9977 0.0023
## class 5:   1.0000 0.0000
## class 6:   0.8305 0.1695
## class 7:   0.8848 0.1152
## class 8:   0.2024 0.7976
## class 9:   0.9969 0.0031
## class 10:  1.0000 0.0000
## class 11:  0.9790 0.0210
## class 12:  1.0000 0.0000
## 
## $vio_c
##             Pr(1)  Pr(2)
## class 1:   1.0000 0.0000
## class 2:   1.0000 0.0000
## class 3:   1.0000 0.0000
## class 4:   0.9993 0.0007
## class 5:   1.0000 0.0000
## class 6:   0.9509 0.0491
## class 7:   1.0000 0.0000
## class 8:   1.0000 0.0000
## class 9:   0.9835 0.0165
## class 10:  1.0000 0.0000
## class 11:  1.0000 0.0000
## class 12:  1.0000 0.0000
## 
## $vio_s
##             Pr(1)  Pr(2)
## class 1:   0.9989 0.0011
## class 2:   1.0000 0.0000
## class 3:   0.9966 0.0034
## class 4:   1.0000 0.0000
## class 5:   1.0000 0.0000
## class 6:   0.9867 0.0133
## class 7:   1.0000 0.0000
## class 8:   0.9821 0.0179
## class 9:   1.0000 0.0000
## class 10:  1.0000 0.0000
## class 11:  1.0000 0.0000
## class 12:  1.0000 0.0000
## 
## $sex_c
##             Pr(1)  Pr(2)
## class 1:   0.9992 0.0008
## class 2:   1.0000 0.0000
## class 3:   0.9333 0.0667
## class 4:   0.9911 0.0089
## class 5:   0.9854 0.0146
## class 6:   0.8783 0.1217
## class 7:   0.9734 0.0266
## class 8:   0.9876 0.0124
## class 9:   0.9380 0.0620
## class 10:  0.9970 0.0030
## class 11:  0.9842 0.0158
## class 12:  0.9968 0.0032
## 
## $sex_s
##             Pr(1)  Pr(2)
## class 1:   0.9975 0.0025
## class 2:   1.0000 0.0000
## class 3:   0.9933 0.0067
## class 4:   0.9984 0.0016
## class 5:   0.9781 0.0219
## class 6:   0.9505 0.0495
## class 7:   0.9854 0.0146
## class 8:   0.9181 0.0819
## class 9:   0.9910 0.0090
## class 10:  0.9996 0.0004
## class 11:  0.9956 0.0044
## class 12:  0.9993 0.0007
## 
## $conflict_col
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.3929 0.5798 0.0272
## class 2:   0.1911 0.1135 0.6955
## class 3:   0.2172 0.6773 0.1055
## class 4:   0.8369 0.1561 0.0070
## class 5:   0.7693 0.1747 0.0560
## class 6:   0.1169 0.5432 0.3399
## class 7:   0.6366 0.3300 0.0334
## class 8:   0.7120 0.2168 0.0712
## class 9:   0.1335 0.6319 0.2347
## class 10:  0.9322 0.0654 0.0024
## class 11:  0.8703 0.1297 0.0000
## class 12:  0.8931 0.1035 0.0034
## 
## $conflict_leid
##             Pr(1)  Pr(2)  Pr(3)
## class 1:   0.1736 0.8099 0.0166
## class 2:   0.0000 0.0938 0.9062
## class 3:   0.6965 0.3035 0.0000
## class 4:   1.0000 0.0000 0.0000
## class 5:   0.8381 0.1165 0.0454
## class 6:   0.2919 0.4968 0.2113
## class 7:   0.2445 0.6015 0.1539
## class 8:   0.1386 0.2092 0.6522
## class 9:   0.9204 0.0760 0.0036
## class 10:  0.9875 0.0120 0.0005
## class 11:  0.6853 0.2938 0.0209
## class 12:  0.9904 0.0096 0.0000
## 
## $steunleid_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.0000 0.5700 0.4244 0.0055
## class 2:   0.3291 0.4757 0.1634 0.0318
## class 3:   0.4659 0.4923 0.0418 0.0000
## class 4:   0.0038 0.4559 0.4821 0.0582
## class 5:   0.0000 0.0220 0.0000 0.9780
## class 6:   0.0095 0.1241 0.6178 0.2486
## class 7:   0.0165 0.0000 0.6165 0.3670
## class 8:   0.0473 0.2081 0.2310 0.5136
## class 9:   0.1013 0.6708 0.2155 0.0123
## class 10:  0.8031 0.1859 0.0110 0.0000
## class 11:  0.0000 0.4170 0.5298 0.0532
## class 12:  0.1009 0.8594 0.0397 0.0000
## 
## $steuncol_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)
## class 1:   0.0970 0.7715 0.1295 0.0020
## class 2:   0.3697 0.5931 0.0372 0.0000
## class 3:   0.4650 0.5260 0.0090 0.0000
## class 4:   0.1138 0.6526 0.2251 0.0085
## class 5:   0.1864 0.0717 0.1890 0.5529
## class 6:   0.0369 0.3257 0.4776 0.1599
## class 7:   0.2125 0.5802 0.1903 0.0170
## class 8:   0.2443 0.6363 0.1108 0.0086
## class 9:   0.0547 0.6553 0.2778 0.0122
## class 10:  0.8273 0.1694 0.0033 0.0000
## class 11:  0.6330 0.3670 0.0000 0.0000
## class 12:  0.1792 0.7947 0.0257 0.0004
## 
## $psyveil_RR
##             Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)
## class 1:   0.0165 0.4224 0.4940 0.0672 0.0000
## class 2:   0.1724 0.5344 0.2550 0.0147 0.0235
## class 3:   0.2511 0.6790 0.0595 0.0000 0.0104
## class 4:   0.0000 0.1974 0.6023 0.1898 0.0105
## class 5:   0.3063 0.3618 0.0284 0.0546 0.2488
## class 6:   0.0048 0.0677 0.3615 0.4133 0.1526
## class 7:   0.0000 0.0000 0.4630 0.4660 0.0710
## class 8:   0.0410 0.1943 0.2617 0.3109 0.1922
## class 9:   0.0155 0.4071 0.4660 0.1012 0.0102
## class 10:  0.5029 0.3920 0.0556 0.0119 0.0376
## class 11:  0.0212 0.6613 0.3085 0.0090 0.0000
## class 12:  0.0395 0.7342 0.2222 0.0041 0.0000
## 
## Estimated class population shares 
##  0.0511 0.0072 0.0255 0.1107 0.0033 0.0132 0.0266 0.0067 0.0219 0.2223 0.0483 0.4631 
##  
## Predicted class memberships (by modal posterior prob.) 
##  0.0517 0.0068 0.0135 0.0936 0.0026 0.0113 0.0229 0.0064 0.0158 0.2026 0.0265 0.5463 
##  
## ========================================================= 
## Fit for 12 latent classes: 
## ========================================================= 
## number of observations: 29923 
## number of fully observed cases: 28262 
## number of estimated parameters: 275 
## residual degrees of freedom: 29648 
## maximum log-likelihood: -118354 
##  
## AIC(12): 237258
## BIC(12): 239542.2
## G^2(12): 4683.012 (Likelihood ratio/deviance statistic) 
## X^2(12): 320954 (Chi-square goodness of fit) 
## </code></pre>
</div>
</div>
<div id="saving-the-models" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Saving the models</h1>
<pre class="r"><code>model3_bpred &lt;- model3_b$predclass
model3_bpost &lt;- model3_b$posterior

lposteriorsmodel3_b &lt;- as.list(as.data.frame(model3_bpost))

pmodel3_bv1 &lt;- lposteriorsmodel3_b[[1]]
pmodel3_bv2 &lt;- lposteriorsmodel3_b[[2]]
pmodel3_bv3 &lt;- lposteriorsmodel3_b[[3]]

model4_bpred &lt;- model4_b$predclass
model4_bpost &lt;- model4_b$posterior

lposteriorsmodel4_b &lt;- as.list(as.data.frame(model4_bpost))

pmodel4_bv1 &lt;- lposteriorsmodel4_b[[1]]
pmodel4_bv2 &lt;- lposteriorsmodel4_b[[2]]
pmodel4_bv3 &lt;- lposteriorsmodel4_b[[3]]
pmodel4_bv4 &lt;- lposteriorsmodel4_b[[4]]


model5_bpred &lt;- model5_b$predclass
model5_bpost &lt;- model5_b$posterior

lposteriorsmodel5_b &lt;- as.list(as.data.frame(model5_bpost))

pmodel5_bv1 &lt;- lposteriorsmodel5_b[[1]]
pmodel5_bv2 &lt;- lposteriorsmodel5_b[[2]]
pmodel5_bv3 &lt;- lposteriorsmodel5_b[[3]]
pmodel5_bv4 &lt;- lposteriorsmodel5_b[[4]]
pmodel5_bv5 &lt;- lposteriorsmodel5_b[[5]]

model6_bpred &lt;- model6_b$predclass
model6_bpost &lt;- model6_b$posterior

lposteriorsmodel6_b &lt;- as.list(as.data.frame(model6_bpost))

pmodel6_bv1 &lt;- lposteriorsmodel6_b[[1]]
pmodel6_bv2 &lt;- lposteriorsmodel6_b[[2]]
pmodel6_bv3 &lt;- lposteriorsmodel6_b[[3]]
pmodel6_bv4 &lt;- lposteriorsmodel6_b[[4]]
pmodel6_bv5 &lt;- lposteriorsmodel6_b[[5]]
pmodel6_bv6 &lt;- lposteriorsmodel6_b[[6]]

model7_bpred &lt;- model7_b$predclass
model7_bpost &lt;- model7_b$posterior

lposteriorsmodel7_b &lt;- as.list(as.data.frame(model7_bpost))

pmodel7_bv1 &lt;- lposteriorsmodel7_b[[1]]
pmodel7_bv2 &lt;- lposteriorsmodel7_b[[2]]
pmodel7_bv3 &lt;- lposteriorsmodel7_b[[3]]
pmodel7_bv4 &lt;- lposteriorsmodel7_b[[4]]
pmodel7_bv5 &lt;- lposteriorsmodel7_b[[5]]
pmodel7_bv6 &lt;- lposteriorsmodel7_b[[6]]
pmodel7_bv7 &lt;- lposteriorsmodel7_b[[7]]

model8_bpred &lt;- model8_b$predclass
model8_bpost &lt;- model8_b$posterior

lposteriorsmodel8_b &lt;- as.list(as.data.frame(model8_bpost))

pmodel8_bv1 &lt;- lposteriorsmodel8_b[[1]]
pmodel8_bv2 &lt;- lposteriorsmodel8_b[[2]]
pmodel8_bv3 &lt;- lposteriorsmodel8_b[[3]]
pmodel8_bv4 &lt;- lposteriorsmodel8_b[[4]]
pmodel8_bv5 &lt;- lposteriorsmodel8_b[[5]]
pmodel8_bv6 &lt;- lposteriorsmodel8_b[[6]]
pmodel8_bv7 &lt;- lposteriorsmodel8_b[[7]]
pmodel8_bv8 &lt;- lposteriorsmodel8_b[[8]]

model9_bpred &lt;- model9_b$predclass
model9_bpost &lt;- model9_b$posterior

lposteriorsmodel9_b &lt;- as.list(as.data.frame(model9_bpost))

pmodel9_bv1 &lt;- lposteriorsmodel9_b[[1]]
pmodel9_bv2 &lt;- lposteriorsmodel9_b[[2]]
pmodel9_bv3 &lt;- lposteriorsmodel9_b[[3]]
pmodel9_bv4 &lt;- lposteriorsmodel9_b[[4]]
pmodel9_bv5 &lt;- lposteriorsmodel9_b[[5]]
pmodel9_bv6 &lt;- lposteriorsmodel9_b[[6]]
pmodel9_bv7 &lt;- lposteriorsmodel9_b[[7]]
pmodel9_bv8 &lt;- lposteriorsmodel9_b[[8]]
pmodel9_bv9 &lt;- lposteriorsmodel9_b[[9]]

model10_bpred &lt;- model10_b$predclass
model10_bpost &lt;- model10_b$posterior

lposteriorsmodel10_b &lt;- as.list(as.data.frame(model10_bpost))

pmodel10_bv1 &lt;- lposteriorsmodel10_b[[1]]
pmodel10_bv2 &lt;- lposteriorsmodel10_b[[2]]
pmodel10_bv3 &lt;- lposteriorsmodel10_b[[3]]
pmodel10_bv4 &lt;- lposteriorsmodel10_b[[4]]
pmodel10_bv5 &lt;- lposteriorsmodel10_b[[5]]
pmodel10_bv6 &lt;- lposteriorsmodel10_b[[6]]
pmodel10_bv7 &lt;- lposteriorsmodel10_b[[7]]
pmodel10_bv8 &lt;- lposteriorsmodel10_b[[8]]
pmodel10_bv9 &lt;- lposteriorsmodel10_b[[9]]
pmodel10_bv10 &lt;- lposteriorsmodel10_b[[10]]

model11_bpred &lt;- model11_b$predclass
model11_bpost &lt;- model11_b$posterior

lposteriorsmodel11_b &lt;- as.list(as.data.frame(model11_bpost))

pmodel11_bv1 &lt;- lposteriorsmodel11_b[[1]]
pmodel11_bv2 &lt;- lposteriorsmodel11_b[[2]]
pmodel11_bv3 &lt;- lposteriorsmodel11_b[[3]]
pmodel11_bv4 &lt;- lposteriorsmodel11_b[[4]]
pmodel11_bv5 &lt;- lposteriorsmodel11_b[[5]]
pmodel11_bv6 &lt;- lposteriorsmodel11_b[[6]]
pmodel11_bv7 &lt;- lposteriorsmodel11_b[[7]]
pmodel11_bv8 &lt;- lposteriorsmodel11_b[[8]]
pmodel11_bv9 &lt;- lposteriorsmodel11_b[[9]]
pmodel11_bv10 &lt;- lposteriorsmodel11_b[[10]]
pmodel11_bv11 &lt;- lposteriorsmodel11_b[[11]]

model12_bpred &lt;- model12_b$predclass
model12_bpost &lt;- model12_b$posterior

lposteriorsmodel12_b &lt;- as.list(as.data.frame(model12_bpost))

pmodel12_bv1 &lt;- lposteriorsmodel12_b[[1]]
pmodel12_bv2 &lt;- lposteriorsmodel12_b[[2]]
pmodel12_bv3 &lt;- lposteriorsmodel12_b[[3]]
pmodel12_bv4 &lt;- lposteriorsmodel12_b[[4]]
pmodel12_bv5 &lt;- lposteriorsmodel12_b[[5]]
pmodel12_bv6 &lt;- lposteriorsmodel12_b[[6]]
pmodel12_bv7 &lt;- lposteriorsmodel12_b[[7]]
pmodel12_bv8 &lt;- lposteriorsmodel12_b[[8]]
pmodel12_bv9 &lt;- lposteriorsmodel12_b[[9]]
pmodel12_bv10 &lt;- lposteriorsmodel12_b[[10]]
pmodel12_bv11 &lt;- lposteriorsmodel12_b[[11]]
pmodel12_bv12 &lt;- lposteriorsmodel12_b[[12]]</code></pre>
<pre class="r"><code>Models_b &lt;- cbind (volgnumm, model3_bpred   ,
                 pmodel3_bv1    ,
                 pmodel3_bv2    ,
                 pmodel3_bv3    ,
                 model4_bpred   ,
                 pmodel4_bv1    ,
                 pmodel4_bv2    ,
                 pmodel4_bv3    ,
                 pmodel4_bv4    ,
                 model5_bpred   ,
                 pmodel5_bv1    ,
                 pmodel5_bv2    ,
                 pmodel5_bv3    ,
                 pmodel5_bv4    ,
                 pmodel5_bv5    ,
                 model6_bpred   ,
                 pmodel6_bv1    ,
                 pmodel6_bv2    ,
                 pmodel6_bv3    ,
                 pmodel6_bv4    ,
                 pmodel6_bv5    ,
                 pmodel6_bv6    ,
                 model7_bpred   ,
                 pmodel7_bv1    ,
                 pmodel7_bv2    ,
                 pmodel7_bv3    ,
                 pmodel7_bv4    ,
                 pmodel7_bv5    ,
                 pmodel7_bv6    ,
                 pmodel7_bv7    ,
                 model8_bpred   ,
                 pmodel8_bv1    ,
                 pmodel8_bv2    ,
                 pmodel8_bv3    ,
                 pmodel8_bv4    ,
                 pmodel8_bv5    ,
                 pmodel8_bv6    ,
                 pmodel8_bv7    ,
                 pmodel8_bv8  ,
                 model9_bpred   ,
                 pmodel9_bv1    ,
                 pmodel9_bv2    ,
                 pmodel9_bv3    ,
                 pmodel9_bv4    ,
                 pmodel9_bv5    ,
                 pmodel9_bv6    ,
                 pmodel9_bv7    ,
                 pmodel9_bv8    ,
                 pmodel9_bv9 ,
                 model10_bpred  ,
                 pmodel10_bv1 ,
                 pmodel10_bv2 ,
                 pmodel10_bv3 ,
                 pmodel10_bv4 ,
                 pmodel10_bv5 ,
                 pmodel10_bv6 ,
                 pmodel10_bv7 ,
                 pmodel10_bv8 ,
                 pmodel10_bv9 ,
                 pmodel10_bv10 ,
                 model11_bpred  ,
                 pmodel11_bv1 ,
                 pmodel11_bv2 ,
                 pmodel11_bv3 ,
                 pmodel11_bv4 ,
                 pmodel11_bv5 ,
                 pmodel11_bv6 ,
                 pmodel11_bv7 ,
                 pmodel11_bv8 ,
                 pmodel11_bv9 ,
                 pmodel11_bv10 ,
                 pmodel11_bv11 ,
                 model12_bpred  ,
                 pmodel12_bv1 ,
                 pmodel12_bv2 ,
                 pmodel12_bv3 ,
                 pmodel12_bv4 ,
                 pmodel12_bv5 ,
                 pmodel12_bv6 ,
                 pmodel12_bv7 ,
                 pmodel12_bv8 ,
                 pmodel12_bv9 ,
                 pmodel12_bv10 ,
                 pmodel12_bv11 ,
                 pmodel12_bv12 )</code></pre>
<pre class="r"><code>models_b &lt;- list(
  model3_b, model4_b, model5_b, model6_b, model7_b,
  model8_b, model9_b, model10_b, model11_b, model12_b
)

model_nums_b &lt;- 3:12

Models_b &lt;- data.frame(volgnumm = volgnumm)

for (i in seq_along(models_b)) {
  
  m &lt;- models_b[[i]]
  num &lt;- model_nums_b[i]
  
  Models_b[[paste0(&quot;model&quot;, num, &quot;_bpred&quot;)]] &lt;- m$predclass
  
  post &lt;- as.data.frame(m$posterior)
  names(post) &lt;- paste0(&quot;pmodel&quot;, num, &quot;_bv&quot;, 1:ncol(post))
  
  Models_b &lt;- cbind(Models_b, post)
}</code></pre>
<pre class="r"><code>NEA2022 &lt;- merge(NEA2022, Models_b, by = &quot;volgnumm&quot;, all.x = TRUE)</code></pre>
</div>
<div id="class-separation" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Class separation</h1>
<pre class="r"><code>max_probs &lt;- apply(model7_bpost, 1, max)

mean(max_probs)</code></pre>
<pre><code>## [1] 0.823411</code></pre>
<pre class="r"><code>median(max_probs)</code></pre>
<pre><code>## [1] 0.8423919</code></pre>
<pre class="r"><code>min(max_probs)</code></pre>
<pre><code>## [1] 0.2991287</code></pre>
<pre class="r"><code>max(max_probs)</code></pre>
<pre><code>## [1] 0.9999996</code></pre>
<pre class="r"><code>K &lt;- 7

mean_posteriors &lt;- numeric(K)

for (k in 1:K) {
  idx &lt;- which(model7_bpred == k)
  mean_posteriors[k] &lt;- mean(model7_bpost[idx, k])
}

names(mean_posteriors) &lt;- paste0(&quot;Class&quot;, 1:K)

mean_posteriors</code></pre>
<pre><code>##    Class1    Class2    Class3    Class4    Class5    Class6    Class7 
## 0.8095255 0.8230372 0.8006172 0.8170047 0.7970947 0.9086849 0.8028509</code></pre>
<pre class="r"><code>ggplot(data.frame(max_probs = max_probs), aes(x = max_probs)) +
  geom_histogram(binwidth = 0.05, fill = &quot;steelblue&quot;, color = &quot;white&quot;) +
  geom_vline(aes(xintercept = mean(max_probs)), 
             color = &quot;red&quot;, linetype = &quot;dashed&quot;, linewidth = 1) +
  labs(title = &quot;Distribution of maximum posterior probabilities&quot;,
       x = &quot;Maximum posterior probability&quot;,
       y = &quot;Number of respondents&quot;) +
  theme_minimal()</code></pre>
<p><img src="LCA_binair_files/figure-html/post%20prob-1.png" width="672" /></p>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model2_b)</code></pre>
<pre><code>## [1] 0.6891182</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model3_b)</code></pre>
<pre><code>## [1] 0.7181333</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model4_b)</code></pre>
<pre><code>## [1] 0.6943218</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model5_b)</code></pre>
<pre><code>## [1] 0.7256171</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model6_b)</code></pre>
<pre><code>## [1] 0.7400825</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model7_b)</code></pre>
<pre><code>## [1] 0.7523642</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model8_b)</code></pre>
<pre><code>## [1] 0.7548263</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model9_b)</code></pre>
<pre><code>## [1] 0.784469</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model10_b)</code></pre>
<pre><code>## [1] 0.7761991</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model11_b)</code></pre>
<pre><code>## [1] 0.7615529</code></pre>
<pre class="r"><code>poLCA.entropy &lt;- function(model) {
  P &lt;- model$posterior
  entropy &lt;- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model12_b)</code></pre>
<pre><code>## [1] 0.7554478</code></pre>
</div>
<div id="plots" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Plots</h1>
<pre class="r"><code>#Recoding variables on scale from 0 to 1

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(bul_c_plot = recode(bul_c, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(bul_s_plot = recode(bul_s, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(int_c_plot = recode(int_c, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(int_s_plot = recode(int_s, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(vio_c_plot = recode(vio_c, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(vio_s_plot = recode(vio_s, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(sex_c_plot = recode(sex_c, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(sex_s_plot = recode(sex_s, `1` = 0, `2` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(conflict_col_plot = recode(conflict_col, `1` = 0, `2` = 0.50, `3` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(conflict_leid_plot = recode(conflict_leid, `1` = 0, `2` = 0.50, `3` = 1))

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(steunleid_plot = (steunleid_RR - 1) / 3)

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(steuncol_plot = (steuncol_RR - 1) / 3)

NEA2022 &lt;- NEA2022 %&gt;%
  mutate(psyveil_plot = (psyveil_RR - 1) / 4)</code></pre>
<div id="model4-1" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Model4</h2>
<pre class="r"><code>model4_bpred &lt;- model4_b$predclass
NEA2022$model4_bpred &lt;- model4_b$predclass
table(model4_b$predclass)</code></pre>
<pre><code>## 
##     1     2     3     4 
##  6159  1836  4618 17310</code></pre>
<pre class="r"><code>prop.table(table(model4_b$predclass)) * 100</code></pre>
<pre><code>## 
##         1         2         3         4 
## 20.582829  6.135748 15.432945 57.848478</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data4 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model4_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model4_bpred), 
                         &quot;1&quot; = &quot;1 (20.58%)&quot;, 
                         &quot;2&quot; = &quot;2 (6.14%)&quot;, 
                         &quot;3&quot; = &quot;3 (15.43%)&quot;, 
                         &quot;4&quot; = &quot;4 (57.85%)&quot;)
  )%&gt;% 
  mutate(class_label = factor(class_label,
                      levels = c(&quot;1 (20.58%)&quot;, &quot;2 (6.14%)&quot;, &quot;3 (15.43%)&quot;, &quot;4 (57.85%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;    = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;   = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;       = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;      = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;      = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;     = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;       = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;      = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot;  = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot; = &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;      = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;     = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;       = &quot;Psychological unsafety&quot;
)

ggplot(plot_data4, aes(x = indicator, y = mean_value,
                      color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;1 (20.58%)&quot;   = &quot;#0072B2&quot;,
      &quot;2 (6.14%)&quot;          = &quot;#D55E00&quot;,
      &quot;3 (15.43%)&quot;   = &quot;#CC79A7&quot;,
      &quot;4 (57.85%)&quot; = &quot;#56B4E9&quot;
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%204-1.png" width="672" /></p>
</div>
<div id="model-5" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Model 5</h2>
<pre class="r"><code>model5_bpred &lt;- model5_b$predclass
NEA2022$model5_bpred &lt;- model5_b$predclass
table(model5_b$predclass)</code></pre>
<pre><code>## 
##     1     2     3     4     5 
##   947 17218  1597  4029  6132</code></pre>
<pre class="r"><code>prop.table(table(model5_b$predclass)) * 100</code></pre>
<pre><code>## 
##         1         2         3         4         5 
##  3.164790 57.541022  5.337032 13.464559 20.492598</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data5 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model5_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model5_bpred), 
                         &quot;1&quot; = &quot;1 (3.16%)&quot;, 
                         &quot;2&quot; = &quot;2 (57.54%)&quot;, 
                         &quot;3&quot; = &quot;3 (5.34%)&quot;, 
                         &quot;4&quot; = &quot;4 (13.46%)&quot;,
                         &quot;5&quot; = &quot;5 (20.49%)&quot;)
  ) %&gt;% 
  mutate(class_label = factor(class_label,
                      levels = c(&quot;1 (3.16%)&quot;, &quot;2 (57.54%)&quot;, &quot;3 (5.34%)&quot;, 
                                 &quot;4 (13.46%)&quot;, &quot;5 (20.49%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;       = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;       = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;       = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;       = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;       = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;       = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;       = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;       = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot;  = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot; = &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;      = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;     = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;       = &quot;Psychological unsafety&quot;
)

ggplot(plot_data5, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;1 (3.16%)&quot;   = &quot;#D55E00&quot;,
      &quot;2 (57.54%)&quot;  = &quot;#56B4E9&quot;,
      &quot;3 (5.34%)&quot;   = &quot;#E69F00&quot;,
      &quot;4 (13.46%)&quot;  = &quot;#CC79A7&quot;,
      &quot;5 (20.49%)&quot;  = &quot;#0072B2&quot;
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%205-1.png" width="672" /></p>
</div>
<div id="model6-1" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Model6</h2>
<pre class="r"><code>model6_bpred &lt;- model6_b$predclass
NEA2022$model6_bpred &lt;- model6_b$predclass
table(model6_b$predclass)</code></pre>
<pre><code>## 
##     1     2     3     4     5     6 
##  1414   608  4098  6106 17167   530</code></pre>
<pre class="r"><code>prop.table(table(model6_b$predclass)) * 100</code></pre>
<pre><code>## 
##         1         2         3         4         5         6 
##  4.725462  2.031882 13.695151 20.405708 57.370585  1.771213</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data6 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model6_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model6_bpred), 
                         &quot;1&quot; = &quot;1 (4.73%)&quot;, 
                         &quot;2&quot; = &quot;2 (2.03%)&quot;, 
                         &quot;3&quot; = &quot;3 (13.70%)&quot;, 
                         &quot;4&quot; = &quot;4 (20.41%)&quot;,
                         &quot;5&quot; = &quot;5 (57.37%)&quot;,
                         &quot;6&quot; = &quot;6 (1.77%)&quot;)
  ) %&gt;% 
  mutate(class_label = factor(class_label,
                      levels = c(&quot;1 (4.73%)&quot;, &quot;2 (2.03%)&quot;, &quot;3 (13.70%)&quot;, 
                                 &quot;4 (20.41%)&quot;, &quot;5 (57.37%)&quot;, &quot;6 (1.77%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;       = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;       = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;       = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;       = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;       = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;       = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;       = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;       = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot;  = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot; = &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;      = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;     = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;       = &quot;Psychological unsafety&quot;
)

ggplot(plot_data6, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;1 (4.73%)&quot;   = &quot;#E69F00&quot;,
      &quot;2 (2.03%)&quot;   = &quot;#D55E00&quot;,
      &quot;3 (13.70%)&quot;  = &quot;#CC79A7&quot;,
      &quot;4 (20.41%)&quot;  = &quot;#0072B2&quot;,
      &quot;5 (57.37%)&quot;  = &quot;#56B4E9&quot;,
      &quot;6 (1.77%)&quot;   = &quot;#000000&quot;
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%206-1.png" width="672" /></p>
</div>
<div id="model7-1" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Model7</h2>
<pre class="r"><code>model7_bpred &lt;- model7_b$predclass
NEA2022$model7_bpred &lt;- model7_b$predclass
table(model7_bpred)</code></pre>
<pre><code>## model7_bpred
##     1     2     3     4     5     6     7 
##  1938   595   884  3114 16758  6091   543</code></pre>
<pre class="r"><code>prop.table(table(model7_b$predclass)) * 100</code></pre>
<pre><code>## 
##         1         2         3         4         5         6         7 
##  6.476623  1.988437  2.954249 10.406711 56.003743 20.355579  1.814658</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data7 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model7_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model7_bpred),
                         &quot;1&quot; = &quot;Short-term conflict (6.48%)&quot;,
                         &quot;2&quot; = &quot;Supervisor unsafety (1.99%)&quot;,
                         &quot;3&quot; = &quot;Coworker unsafety (2.95%)&quot;,
                         &quot;4&quot; = &quot;Unsafe social climate (10.41%)&quot;,
                         &quot;5&quot; = &quot;Safe (56.00%)&quot;,
                         &quot;6&quot; = &quot;Highly safe (20.36%)&quot;,
                         &quot;7&quot; = &quot;Overall unsafe (1.81%)&quot;)
  ) %&gt;%
  mutate(class_label = factor(class_label,
                              levels = c(&quot;Highly safe (20.36%)&quot;, 
                                         &quot;Safe (56.00%)&quot;,
                                         &quot;Short-term conflict (6.48%)&quot;, 
                                         &quot;Unsafe social climate (10.41%)&quot;, 
                                         &quot;Coworker unsafety (2.95%)&quot;, 
                                         &quot;Supervisor unsafety (1.99%)&quot;, 
                                         &quot;Overall unsafe (1.81%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;    = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;   = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;       = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;      = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;      = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;     = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;       = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;      = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot;  = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot; = &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;      = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;     = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;       = &quot;Psychological unsafety&quot;
)

ggplot(plot_data7, aes(x = indicator, y = mean_value,
                      color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;Highly safe (20.36%)&quot;   = &quot;#0072B2&quot;,
      &quot;Safe (56.00%)&quot;          = &quot;#56B4E9&quot;,
      &quot;Short-term conflict (6.48%)&quot;   = &quot;#009E73&quot;,
      &quot;Unsafe social climate (10.41%)&quot; = &quot;#CC79A7&quot;,
      &quot;Coworker unsafety (2.95%)&quot;     = &quot;#E69F00&quot;,
      &quot;Supervisor unsafety (1.99%)&quot;   = &quot;#D55E00&quot;,
      &quot;Overall unsafe (1.81%)&quot;        = &quot;#000000&quot; 
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%207-1.png" width="672" /></p>
</div>
<div id="model8-1" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Model8</h2>
<pre class="r"><code>model8_bpred &lt;- model8_b$predclass
NEA2022$model8_bpred &lt;- model8_b$predclass
table(model8_b$predclass)</code></pre>
<pre><code>## 
##     1     2     3     4     5     6     7     8 
##  6114   523  1918 16649  3112   826   500   281</code></pre>
<pre class="r"><code>prop.table(table(model8_b$predclass)) * 100</code></pre>
<pre><code>## 
##         1         2         3         4         5         6         7         8 
## 20.432443  1.747819  6.409785 55.639475 10.400027  2.760418  1.670955  0.939077</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data8 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model8_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model8_bpred), 
                         &quot;1&quot; = &quot;1 (20.43%)&quot;, 
                         &quot;2&quot; = &quot;2 (1.75%)&quot;, 
                         &quot;3&quot; = &quot;3 (6.41%)&quot;, 
                         &quot;4&quot; = &quot;4 (55.64%)&quot;,
                         &quot;5&quot; = &quot;5 (10.40%)&quot;,
                         &quot;6&quot; = &quot;6 (2.76%)&quot;,
                         &quot;7&quot; = &quot;7 (1.67%)&quot;,
                         &quot;8&quot; = &quot;8 (0.94%)&quot;)
  ) %&gt;% 
  mutate(class_label = factor(class_label,
                      levels = c(&quot;1 (20.43%)&quot;, &quot;2 (1.75%)&quot;, &quot;3 (6.41%)&quot;, 
                                 &quot;4 (55.64%)&quot;, &quot;5 (10.40%)&quot;, &quot;6 (2.76%)&quot;, 
                                 &quot;7 (1.67%)&quot;, &quot;8 (0.94%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;        = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;        = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;        = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;        = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;        = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;        = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;        = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;        = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot; = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot;= &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;     = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;    = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;      = &quot;Psychological unsafety&quot;
)

ggplot(plot_data8, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;1 (20.43%)&quot; = &quot;#0072B2&quot;,
      &quot;2 (1.75%)&quot;  = &quot;#D55E00&quot;,
      &quot;3 (6.41%)&quot;  = &quot;#009E73&quot;,
      &quot;4 (55.64%)&quot; = &quot;#56B4E9&quot;,
      &quot;5 (10.40%)&quot; = &quot;#CC79A7&quot;,
      &quot;6 (2.76%)&quot;  = &quot;#E69F00&quot;,
      &quot;7 (1.67%)&quot;  = &quot;#000000&quot;,
      &quot;8 (0.94%)&quot;  = &quot;#F0E442&quot;
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%208-1.png" width="672" /></p>
</div>
<div id="model9-1" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Model9</h2>
<pre class="r"><code>model9_bpred &lt;- model9_b$predclass
NEA2022$model9_bpred &lt;- model9_b$predclass
table(model9_b$predclass)</code></pre>
<pre><code>## 
##     1     2     3     4     5     6     7     8     9 
##  3390   646  1682   488   113   479 16703  6105   317</code></pre>
<pre class="r"><code>prop.table(table(model9_b$predclass)) * 100</code></pre>
<pre><code>## 
##          1          2          3          4          5          6          7 
## 11.3290780  2.1588744  5.6210941  1.6308525  0.3776359  1.6007753 55.8199378 
##          8          9 
## 20.4023661  1.0593858</code></pre>
<pre class="r"><code>vars &lt;- c(&quot;bul_c_plot&quot;, &quot;bul_s_plot&quot;, &quot;int_c_plot&quot;, &quot;int_s_plot&quot;,
          &quot;vio_c_plot&quot;, &quot;vio_s_plot&quot;, &quot;sex_c_plot&quot;, &quot;sex_s_plot&quot;,
          &quot;conflict_col_plot&quot;, &quot;conflict_leid_plot&quot;, 
          &quot;steuncol_plot&quot;, &quot;steunleid_plot&quot;, &quot;psyveil_plot&quot;)

plot_data9 &lt;- NEA2022 %&gt;%
  pivot_longer(cols = all_of(vars), names_to = &quot;indicator&quot;, values_to = &quot;value&quot;) %&gt;%
  group_by(model9_bpred, indicator) %&gt;%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model9_bpred), 
                         &quot;1&quot; = &quot;1 (11.33%)&quot;, 
                         &quot;2&quot; = &quot;2 (2.16%)&quot;, 
                         &quot;3&quot; = &quot;3 (5.62%)&quot;, 
                         &quot;4&quot; = &quot;4 (1.63%)&quot;,
                         &quot;5&quot; = &quot;5 (0.38%)&quot;,
                         &quot;6&quot; = &quot;6 (1.60%)&quot;,
                         &quot;7&quot; = &quot;7 (55.82%)&quot;,
                         &quot;8&quot; = &quot;8 (20.40%)&quot;,
                         &quot;9&quot; = &quot;9 (1.06%)&quot;)
  ) %&gt;% 
  mutate(class_label = factor(class_label,
                      levels = c(&quot;1 (11.33%)&quot;, &quot;2 (2.16%)&quot;, &quot;3 (5.62%)&quot;, &quot;4 (1.63%)&quot;,
                                 &quot;5 (0.38%)&quot;, &quot;6 (1.60%)&quot;, &quot;7 (55.82%)&quot;, 
                                 &quot;8 (20.40%)&quot;, &quot;9 (1.06%)&quot;)))

indicator_labels &lt;- c(
  &quot;bul_c_plot&quot;        = &quot;Bullying C&quot;,
  &quot;bul_s_plot&quot;        = &quot;Bullying S&quot;,
  &quot;int_c_plot&quot;        = &quot;Intimidation C&quot;,
  &quot;int_s_plot&quot;        = &quot;Intimidation S&quot;,
  &quot;sex_c_plot&quot;        = &quot;Unwanted sexual attention C&quot;,
  &quot;sex_s_plot&quot;        = &quot;Unwanted sexual attention S&quot;,
  &quot;vio_c_plot&quot;        = &quot;Violence C&quot;,
  &quot;vio_s_plot&quot;        = &quot;Violence S&quot;,
  &quot;conflict_col_plot&quot; = &quot;Conflict C&quot;,
  &quot;conflict_leid_plot&quot;= &quot;Conflict S&quot;,
  &quot;steuncol_plot&quot;     = &quot;Incivility C&quot;,
  &quot;steunleid_plot&quot;    = &quot;Incivility S&quot;,
  &quot;psyveil_plot&quot;      = &quot;Psychological unsafety&quot;
)

ggplot(plot_data9, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      &quot;1 (11.33%)&quot; = &quot;#CC79A7&quot;,
      &quot;2 (2.16%)&quot;  = &quot;#E69F00&quot;,
      &quot;3 (5.62%)&quot;  = &quot;#009E73&quot;,
      &quot;4 (1.63%)&quot;  = &quot;#000000&quot;,
      &quot;5 (0.38%)&quot;  = &quot;#999999&quot;,
      &quot;6 (1.60%)&quot;  = &quot;#D55E00&quot;,
      &quot;7 (55.82%)&quot; = &quot;#56B4E9&quot;,
      &quot;8 (20.40%)&quot; = &quot;#0072B2&quot;,
      &quot;9 (1.06%)&quot;  = &quot;#F0E442&quot;
    )
  ) +
  labs(x = NULL, y = &quot;Mean score&quot;, color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = &quot;bottom&quot;,
    legend.text = element_text(size = 11)
  )</code></pre>
<p><img src="LCA_binair_files/figure-html/plot%209-1.png" width="672" /></p>
</div>
</div>

<div id="rmd-source-code">---
title: "LCA binair"
output: html_document
date: "2025-06-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r loading packages, warning=FALSE, results='hide', message=FALSE}
library("formatR")
library("foreign")
library("ggplot2")
library("lme4")
library("poLCA")
library("reprex")
library("tidyr")
library("klippy")
library("dplyr")
library("haven")
library("psych")
```


<br><br> **Loading the data**

```{r loading data, cache=TRUE, results='hide', warning=FALSE, message=FALSE}
NEA2022 <- readRDS("data/processed/NEA1009.rds")

attach(NEA2022)
set.seed(123)
```

<br><br> **Recoding into binary variables**

```{r recoding binary, cache=TRUE}
table(NEA2022$pesten_col)

NEA2022 <- NEA2022 %>%
  mutate(bul_c = case_when(
    pesten_col == 1 ~ 1,
    pesten_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$bul_c)


table(NEA2022$pesten_leid)

NEA2022 <- NEA2022 %>%
  mutate(bul_s = case_when(
    pesten_leid == 1 ~ 1,
    pesten_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$bul_s)

table(NEA2022$intimidation_col)

NEA2022 <- NEA2022 %>%
  mutate(int_c = case_when(
    intimidation_col == 1 ~ 1,
    intimidation_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$int_c)

table(NEA2022$intimidation_leid)

NEA2022 <- NEA2022 %>%
  mutate(int_s = case_when(
    intimidation_leid == 1 ~ 1,
    intimidation_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$int_s)

table(NEA2022$seks_col)

NEA2022 <- NEA2022 %>%
  mutate(sex_c = case_when(
    seks_col == 1 ~ 1,
    seks_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$sex_c)

table(NEA2022$seks_leid)

NEA2022 <- NEA2022 %>%
  mutate(sex_s = case_when(
    seks_leid == 1 ~ 1,
    seks_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$sex_s)

table(NEA2022$geweld_col)

NEA2022 <- NEA2022 %>%
  mutate(vio_c = case_when(
    geweld_col == 1 ~ 1,
    geweld_col %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$vio_c)

table(NEA2022$geweld_leid)

NEA2022 <- NEA2022 %>%
  mutate(vio_s = case_when(
    geweld_leid == 1 ~ 1,
    geweld_leid %in% c(2, 3, 4) ~ 2,
    TRUE ~ NA_real_ 
  ))

table(NEA2022$vio_s)
```

# Latent class analysis

```{r data items, cache=TRUE, warning=FALSE}
attach(NEA2022)
data_b <- data.frame(bul_c, bul_s, int_c, int_s, vio_c, vio_s, sex_c, sex_s, conflict_col, conflict_leid, steunleid_RR, steuncol_RR, psyveil_RR)

items_b <- cbind(bul_c, bul_s, int_c, int_s, vio_c, vio_s, sex_c, sex_s, conflict_col, conflict_leid, steunleid_RR, steuncol_RR, psyveil_RR) ~ 1
```

## Model1
```{r model 1, cache=TRUE}
model1_b <- poLCA(items_b, data_b, nclass = 1, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model2

```{r model 2, cache=TRUE}
model2_b <- poLCA(items_b, data_b, nclass = 2, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model3

```{r model 3, cache=TRUE}
model3_b <- poLCA(items_b, data_b, nclass = 3, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model4

```{r model 4, cache=TRUE}
model4_b <- poLCA(items_b, data_b, nclass = 4, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model5

```{r model 5, cache=TRUE}
model5_b <- poLCA(items_b, data_b, nclass = 5, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model6

```{r model 6, cache=TRUE}
model6_b <- poLCA(items_b, data_b, nclass = 6, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model7

```{r model 7, cache=TRUE}
model7_b <- poLCA(items_b, data_b, nclass = 7, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model8

```{r model 8, cache=TRUE}
model8_b <- poLCA(items_b, data_b, nclass = 8, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model9

```{r model 9, cache=TRUE}
model9_b <- poLCA(items_b, data_b, nclass = 9, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model10

```{r model 10, cache=TRUE}
model10_b <- poLCA(items_b, data_b, nclass = 10, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model11

```{r model 11, cache=TRUE}
model11_b <- poLCA(items_b, data_b, nclass = 11, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```

## Model12

```{r model 12, cache=TRUE}
model12_b <- poLCA(items_b, data_b, nclass = 12, maxiter = 5000, nrep = 10, graphs=FALSE, na.rm = FALSE)
```


# Saving the models

```{r saving models, cache=TRUE}
model3_bpred <- model3_b$predclass
model3_bpost <- model3_b$posterior

lposteriorsmodel3_b <- as.list(as.data.frame(model3_bpost))

pmodel3_bv1 <- lposteriorsmodel3_b[[1]]
pmodel3_bv2 <- lposteriorsmodel3_b[[2]]
pmodel3_bv3 <- lposteriorsmodel3_b[[3]]

model4_bpred <- model4_b$predclass
model4_bpost <- model4_b$posterior

lposteriorsmodel4_b <- as.list(as.data.frame(model4_bpost))

pmodel4_bv1 <- lposteriorsmodel4_b[[1]]
pmodel4_bv2 <- lposteriorsmodel4_b[[2]]
pmodel4_bv3 <- lposteriorsmodel4_b[[3]]
pmodel4_bv4 <- lposteriorsmodel4_b[[4]]


model5_bpred <- model5_b$predclass
model5_bpost <- model5_b$posterior

lposteriorsmodel5_b <- as.list(as.data.frame(model5_bpost))

pmodel5_bv1 <- lposteriorsmodel5_b[[1]]
pmodel5_bv2 <- lposteriorsmodel5_b[[2]]
pmodel5_bv3 <- lposteriorsmodel5_b[[3]]
pmodel5_bv4 <- lposteriorsmodel5_b[[4]]
pmodel5_bv5 <- lposteriorsmodel5_b[[5]]

model6_bpred <- model6_b$predclass
model6_bpost <- model6_b$posterior

lposteriorsmodel6_b <- as.list(as.data.frame(model6_bpost))

pmodel6_bv1 <- lposteriorsmodel6_b[[1]]
pmodel6_bv2 <- lposteriorsmodel6_b[[2]]
pmodel6_bv3 <- lposteriorsmodel6_b[[3]]
pmodel6_bv4 <- lposteriorsmodel6_b[[4]]
pmodel6_bv5 <- lposteriorsmodel6_b[[5]]
pmodel6_bv6 <- lposteriorsmodel6_b[[6]]

model7_bpred <- model7_b$predclass
model7_bpost <- model7_b$posterior

lposteriorsmodel7_b <- as.list(as.data.frame(model7_bpost))

pmodel7_bv1 <- lposteriorsmodel7_b[[1]]
pmodel7_bv2 <- lposteriorsmodel7_b[[2]]
pmodel7_bv3 <- lposteriorsmodel7_b[[3]]
pmodel7_bv4 <- lposteriorsmodel7_b[[4]]
pmodel7_bv5 <- lposteriorsmodel7_b[[5]]
pmodel7_bv6 <- lposteriorsmodel7_b[[6]]
pmodel7_bv7 <- lposteriorsmodel7_b[[7]]

model8_bpred <- model8_b$predclass
model8_bpost <- model8_b$posterior

lposteriorsmodel8_b <- as.list(as.data.frame(model8_bpost))

pmodel8_bv1 <- lposteriorsmodel8_b[[1]]
pmodel8_bv2 <- lposteriorsmodel8_b[[2]]
pmodel8_bv3 <- lposteriorsmodel8_b[[3]]
pmodel8_bv4 <- lposteriorsmodel8_b[[4]]
pmodel8_bv5 <- lposteriorsmodel8_b[[5]]
pmodel8_bv6 <- lposteriorsmodel8_b[[6]]
pmodel8_bv7 <- lposteriorsmodel8_b[[7]]
pmodel8_bv8 <- lposteriorsmodel8_b[[8]]

model9_bpred <- model9_b$predclass
model9_bpost <- model9_b$posterior

lposteriorsmodel9_b <- as.list(as.data.frame(model9_bpost))

pmodel9_bv1 <- lposteriorsmodel9_b[[1]]
pmodel9_bv2 <- lposteriorsmodel9_b[[2]]
pmodel9_bv3 <- lposteriorsmodel9_b[[3]]
pmodel9_bv4 <- lposteriorsmodel9_b[[4]]
pmodel9_bv5 <- lposteriorsmodel9_b[[5]]
pmodel9_bv6 <- lposteriorsmodel9_b[[6]]
pmodel9_bv7 <- lposteriorsmodel9_b[[7]]
pmodel9_bv8 <- lposteriorsmodel9_b[[8]]
pmodel9_bv9 <- lposteriorsmodel9_b[[9]]

model10_bpred <- model10_b$predclass
model10_bpost <- model10_b$posterior

lposteriorsmodel10_b <- as.list(as.data.frame(model10_bpost))

pmodel10_bv1 <- lposteriorsmodel10_b[[1]]
pmodel10_bv2 <- lposteriorsmodel10_b[[2]]
pmodel10_bv3 <- lposteriorsmodel10_b[[3]]
pmodel10_bv4 <- lposteriorsmodel10_b[[4]]
pmodel10_bv5 <- lposteriorsmodel10_b[[5]]
pmodel10_bv6 <- lposteriorsmodel10_b[[6]]
pmodel10_bv7 <- lposteriorsmodel10_b[[7]]
pmodel10_bv8 <- lposteriorsmodel10_b[[8]]
pmodel10_bv9 <- lposteriorsmodel10_b[[9]]
pmodel10_bv10 <- lposteriorsmodel10_b[[10]]

model11_bpred <- model11_b$predclass
model11_bpost <- model11_b$posterior

lposteriorsmodel11_b <- as.list(as.data.frame(model11_bpost))

pmodel11_bv1 <- lposteriorsmodel11_b[[1]]
pmodel11_bv2 <- lposteriorsmodel11_b[[2]]
pmodel11_bv3 <- lposteriorsmodel11_b[[3]]
pmodel11_bv4 <- lposteriorsmodel11_b[[4]]
pmodel11_bv5 <- lposteriorsmodel11_b[[5]]
pmodel11_bv6 <- lposteriorsmodel11_b[[6]]
pmodel11_bv7 <- lposteriorsmodel11_b[[7]]
pmodel11_bv8 <- lposteriorsmodel11_b[[8]]
pmodel11_bv9 <- lposteriorsmodel11_b[[9]]
pmodel11_bv10 <- lposteriorsmodel11_b[[10]]
pmodel11_bv11 <- lposteriorsmodel11_b[[11]]

model12_bpred <- model12_b$predclass
model12_bpost <- model12_b$posterior

lposteriorsmodel12_b <- as.list(as.data.frame(model12_bpost))

pmodel12_bv1 <- lposteriorsmodel12_b[[1]]
pmodel12_bv2 <- lposteriorsmodel12_b[[2]]
pmodel12_bv3 <- lposteriorsmodel12_b[[3]]
pmodel12_bv4 <- lposteriorsmodel12_b[[4]]
pmodel12_bv5 <- lposteriorsmodel12_b[[5]]
pmodel12_bv6 <- lposteriorsmodel12_b[[6]]
pmodel12_bv7 <- lposteriorsmodel12_b[[7]]
pmodel12_bv8 <- lposteriorsmodel12_b[[8]]
pmodel12_bv9 <- lposteriorsmodel12_b[[9]]
pmodel12_bv10 <- lposteriorsmodel12_b[[10]]
pmodel12_bv11 <- lposteriorsmodel12_b[[11]]
pmodel12_bv12 <- lposteriorsmodel12_b[[12]]
```

```{r saving models 2, cache=TRUE}
Models_b <- cbind (volgnumm, model3_bpred	,
                 pmodel3_bv1	,
                 pmodel3_bv2	,
                 pmodel3_bv3	,
                 model4_bpred	,
                 pmodel4_bv1	,
                 pmodel4_bv2	,
                 pmodel4_bv3	,
                 pmodel4_bv4	,
                 model5_bpred	,
                 pmodel5_bv1	,
                 pmodel5_bv2	,
                 pmodel5_bv3	,
                 pmodel5_bv4	,
                 pmodel5_bv5	,
                 model6_bpred	,
                 pmodel6_bv1	,
                 pmodel6_bv2	,
                 pmodel6_bv3	,
                 pmodel6_bv4	,
                 pmodel6_bv5	,
                 pmodel6_bv6	,
                 model7_bpred	,
                 pmodel7_bv1	,
                 pmodel7_bv2	,
                 pmodel7_bv3	,
                 pmodel7_bv4	,
                 pmodel7_bv5	,
                 pmodel7_bv6	,
                 pmodel7_bv7	,
                 model8_bpred	,
                 pmodel8_bv1	,
                 pmodel8_bv2	,
                 pmodel8_bv3	,
                 pmodel8_bv4	,
                 pmodel8_bv5	,
                 pmodel8_bv6	,
                 pmodel8_bv7	,
                 pmodel8_bv8  ,
                 model9_bpred	,
                 pmodel9_bv1	,
                 pmodel9_bv2	,
                 pmodel9_bv3	,
                 pmodel9_bv4	,
                 pmodel9_bv5	,
                 pmodel9_bv6	,
                 pmodel9_bv7	,
                 pmodel9_bv8	,
                 pmodel9_bv9 ,
                 model10_bpred	,
                 pmodel10_bv1 ,
                 pmodel10_bv2 ,
                 pmodel10_bv3 ,
                 pmodel10_bv4 ,
                 pmodel10_bv5 ,
                 pmodel10_bv6 ,
                 pmodel10_bv7 ,
                 pmodel10_bv8 ,
                 pmodel10_bv9 ,
                 pmodel10_bv10 ,
                 model11_bpred	,
                 pmodel11_bv1 ,
                 pmodel11_bv2 ,
                 pmodel11_bv3 ,
                 pmodel11_bv4 ,
                 pmodel11_bv5 ,
                 pmodel11_bv6 ,
                 pmodel11_bv7 ,
                 pmodel11_bv8 ,
                 pmodel11_bv9 ,
                 pmodel11_bv10 ,
                 pmodel11_bv11 ,
                 model12_bpred	,
                 pmodel12_bv1 ,
                 pmodel12_bv2 ,
                 pmodel12_bv3 ,
                 pmodel12_bv4 ,
                 pmodel12_bv5 ,
                 pmodel12_bv6 ,
                 pmodel12_bv7 ,
                 pmodel12_bv8 ,
                 pmodel12_bv9 ,
                 pmodel12_bv10 ,
                 pmodel12_bv11 ,
                 pmodel12_bv12 )
```


```{r}
models_b <- list(
  model3_b, model4_b, model5_b, model6_b, model7_b,
  model8_b, model9_b, model10_b, model11_b, model12_b
)

model_nums_b <- 3:12

Models_b <- data.frame(volgnumm = volgnumm)

for (i in seq_along(models_b)) {
  
  m <- models_b[[i]]
  num <- model_nums_b[i]
  
  Models_b[[paste0("model", num, "_bpred")]] <- m$predclass
  
  post <- as.data.frame(m$posterior)
  names(post) <- paste0("pmodel", num, "_bv", 1:ncol(post))
  
  Models_b <- cbind(Models_b, post)
}

```

```{r}
NEA2022 <- merge(NEA2022, Models_b, by = "volgnumm", all.x = TRUE)
```


# Class separation


```{r post prob, cache=TRUE}
max_probs <- apply(model7_bpost, 1, max)

mean(max_probs)
median(max_probs)
min(max_probs)
max(max_probs)

K <- 7

mean_posteriors <- numeric(K)

for (k in 1:K) {
  idx <- which(model7_bpred == k)
  mean_posteriors[k] <- mean(model7_bpost[idx, k])
}

names(mean_posteriors) <- paste0("Class", 1:K)

mean_posteriors


ggplot(data.frame(max_probs = max_probs), aes(x = max_probs)) +
  geom_histogram(binwidth = 0.05, fill = "steelblue", color = "white") +
  geom_vline(aes(xintercept = mean(max_probs)), 
             color = "red", linetype = "dashed", linewidth = 1) +
  labs(title = "Distribution of maximum posterior probabilities",
       x = "Maximum posterior probability",
       y = "Number of respondents") +
  theme_minimal()
```

```{r entropy, cache=TRUE}
poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model2_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model3_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model4_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model5_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model6_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model7_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model8_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model9_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model10_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model11_b)

poLCA.entropy <- function(model) {
  P <- model$posterior
  entropy <- sum(-P * log(P), na.rm=TRUE) / (nrow(P) * log(ncol(P)))
  return(1 - entropy)
}
poLCA.entropy(model12_b)
```



# Plots

```{r rocoding plot, echo=TRUE}
#Recoding variables on scale from 0 to 1

NEA2022 <- NEA2022 %>%
  mutate(bul_c_plot = recode(bul_c, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(bul_s_plot = recode(bul_s, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(int_c_plot = recode(int_c, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(int_s_plot = recode(int_s, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(vio_c_plot = recode(vio_c, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(vio_s_plot = recode(vio_s, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(sex_c_plot = recode(sex_c, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(sex_s_plot = recode(sex_s, `1` = 0, `2` = 1))

NEA2022 <- NEA2022 %>%
  mutate(conflict_col_plot = recode(conflict_col, `1` = 0, `2` = 0.50, `3` = 1))

NEA2022 <- NEA2022 %>%
  mutate(conflict_leid_plot = recode(conflict_leid, `1` = 0, `2` = 0.50, `3` = 1))

NEA2022 <- NEA2022 %>%
  mutate(steunleid_plot = (steunleid_RR - 1) / 3)

NEA2022 <- NEA2022 %>%
  mutate(steuncol_plot = (steuncol_RR - 1) / 3)

NEA2022 <- NEA2022 %>%
  mutate(psyveil_plot = (psyveil_RR - 1) / 4)

```



## Model4

```{r plot 4, echo=TRUE}
model4_bpred <- model4_b$predclass
NEA2022$model4_bpred <- model4_b$predclass
table(model4_b$predclass)
prop.table(table(model4_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data4 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model4_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model4_bpred), 
                         "1" = "1 (20.58%)", 
                         "2" = "2 (6.14%)", 
                         "3" = "3 (15.43%)", 
                         "4" = "4 (57.85%)")
  )%>% 
  mutate(class_label = factor(class_label,
                      levels = c("1 (20.58%)", "2 (6.14%)", "3 (15.43%)", "4 (57.85%)")))

indicator_labels <- c(
  "bul_c_plot"    = "Bullying C",
  "bul_s_plot"   = "Bullying S",
  "int_c_plot"       = "Intimidation C",
  "int_s_plot"      = "Intimidation S",
  "sex_c_plot"      = "Unwanted sexual attention C",
  "sex_s_plot"     = "Unwanted sexual attention S",
  "vio_c_plot"       = "Violence C",
  "vio_s_plot"      = "Violence S",
  "conflict_col_plot"  = "Conflict C",
  "conflict_leid_plot" = "Conflict S",
  "steuncol_plot"      = "Incivility C",
  "steunleid_plot"     = "Incivility S",
  "psyveil_plot"       = "Psychological unsafety"
)

ggplot(plot_data4, aes(x = indicator, y = mean_value,
                      color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "1 (20.58%)"   = "#0072B2",
      "2 (6.14%)"          = "#D55E00",
      "3 (15.43%)"   = "#CC79A7",
      "4 (57.85%)" = "#56B4E9"
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )

```

## Model 5

```{r plot 5, echo=TRUE}
model5_bpred <- model5_b$predclass
NEA2022$model5_bpred <- model5_b$predclass
table(model5_b$predclass)
prop.table(table(model5_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data5 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model5_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model5_bpred), 
                         "1" = "1 (3.16%)", 
                         "2" = "2 (57.54%)", 
                         "3" = "3 (5.34%)", 
                         "4" = "4 (13.46%)",
                         "5" = "5 (20.49%)")
  ) %>% 
  mutate(class_label = factor(class_label,
                      levels = c("1 (3.16%)", "2 (57.54%)", "3 (5.34%)", 
                                 "4 (13.46%)", "5 (20.49%)")))

indicator_labels <- c(
  "bul_c_plot"       = "Bullying C",
  "bul_s_plot"       = "Bullying S",
  "int_c_plot"       = "Intimidation C",
  "int_s_plot"       = "Intimidation S",
  "sex_c_plot"       = "Unwanted sexual attention C",
  "sex_s_plot"       = "Unwanted sexual attention S",
  "vio_c_plot"       = "Violence C",
  "vio_s_plot"       = "Violence S",
  "conflict_col_plot"  = "Conflict C",
  "conflict_leid_plot" = "Conflict S",
  "steuncol_plot"      = "Incivility C",
  "steunleid_plot"     = "Incivility S",
  "psyveil_plot"       = "Psychological unsafety"
)

ggplot(plot_data5, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "1 (3.16%)"   = "#D55E00",
      "2 (57.54%)"  = "#56B4E9",
      "3 (5.34%)"   = "#E69F00",
      "4 (13.46%)"  = "#CC79A7",
      "5 (20.49%)"  = "#0072B2"
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )

```


## Model6


```{r plot 6, echo=TRUE}
model6_bpred <- model6_b$predclass
NEA2022$model6_bpred <- model6_b$predclass
table(model6_b$predclass)
prop.table(table(model6_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data6 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model6_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model6_bpred), 
                         "1" = "1 (4.73%)", 
                         "2" = "2 (2.03%)", 
                         "3" = "3 (13.70%)", 
                         "4" = "4 (20.41%)",
                         "5" = "5 (57.37%)",
                         "6" = "6 (1.77%)")
  ) %>% 
  mutate(class_label = factor(class_label,
                      levels = c("1 (4.73%)", "2 (2.03%)", "3 (13.70%)", 
                                 "4 (20.41%)", "5 (57.37%)", "6 (1.77%)")))

indicator_labels <- c(
  "bul_c_plot"       = "Bullying C",
  "bul_s_plot"       = "Bullying S",
  "int_c_plot"       = "Intimidation C",
  "int_s_plot"       = "Intimidation S",
  "sex_c_plot"       = "Unwanted sexual attention C",
  "sex_s_plot"       = "Unwanted sexual attention S",
  "vio_c_plot"       = "Violence C",
  "vio_s_plot"       = "Violence S",
  "conflict_col_plot"  = "Conflict C",
  "conflict_leid_plot" = "Conflict S",
  "steuncol_plot"      = "Incivility C",
  "steunleid_plot"     = "Incivility S",
  "psyveil_plot"       = "Psychological unsafety"
)

ggplot(plot_data6, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "1 (4.73%)"   = "#E69F00",
      "2 (2.03%)"   = "#D55E00",
      "3 (13.70%)"  = "#CC79A7",
      "4 (20.41%)"  = "#0072B2",
      "5 (57.37%)"  = "#56B4E9",
      "6 (1.77%)"   = "#000000"
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )

```


## Model7

```{r plot 7, echo=TRUE}
model7_bpred <- model7_b$predclass
NEA2022$model7_bpred <- model7_b$predclass
table(model7_bpred)
prop.table(table(model7_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data7 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model7_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model7_bpred),
                         "1" = "Short-term conflict (6.48%)",
                         "2" = "Supervisor unsafety (1.99%)",
                         "3" = "Coworker unsafety (2.95%)",
                         "4" = "Unsafe social climate (10.41%)",
                         "5" = "Safe (56.00%)",
                         "6" = "Highly safe (20.36%)",
                         "7" = "Overall unsafe (1.81%)")
  ) %>%
  mutate(class_label = factor(class_label,
                              levels = c("Highly safe (20.36%)", 
                                         "Safe (56.00%)",
                                         "Short-term conflict (6.48%)", 
                                         "Unsafe social climate (10.41%)", 
                                         "Coworker unsafety (2.95%)", 
                                         "Supervisor unsafety (1.99%)", 
                                         "Overall unsafe (1.81%)")))

indicator_labels <- c(
  "bul_c_plot"    = "Bullying C",
  "bul_s_plot"   = "Bullying S",
  "int_c_plot"       = "Intimidation C",
  "int_s_plot"      = "Intimidation S",
  "sex_c_plot"      = "Unwanted sexual attention C",
  "sex_s_plot"     = "Unwanted sexual attention S",
  "vio_c_plot"       = "Violence C",
  "vio_s_plot"      = "Violence S",
  "conflict_col_plot"  = "Conflict C",
  "conflict_leid_plot" = "Conflict S",
  "steuncol_plot"      = "Incivility C",
  "steunleid_plot"     = "Incivility S",
  "psyveil_plot"       = "Psychological unsafety"
)

ggplot(plot_data7, aes(x = indicator, y = mean_value,
                      color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "Highly safe (20.36%)"   = "#0072B2",
      "Safe (56.00%)"          = "#56B4E9",
      "Short-term conflict (6.48%)"   = "#009E73",
      "Unsafe social climate (10.41%)" = "#CC79A7",
      "Coworker unsafety (2.95%)"     = "#E69F00",
      "Supervisor unsafety (1.99%)"   = "#D55E00",
      "Overall unsafe (1.81%)"        = "#000000" 
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )
```

## Model8


```{r plot 8, echo=TRUE}
model8_bpred <- model8_b$predclass
NEA2022$model8_bpred <- model8_b$predclass
table(model8_b$predclass)
prop.table(table(model8_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data8 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model8_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model8_bpred), 
                         "1" = "1 (20.43%)", 
                         "2" = "2 (1.75%)", 
                         "3" = "3 (6.41%)", 
                         "4" = "4 (55.64%)",
                         "5" = "5 (10.40%)",
                         "6" = "6 (2.76%)",
                         "7" = "7 (1.67%)",
                         "8" = "8 (0.94%)")
  ) %>% 
  mutate(class_label = factor(class_label,
                      levels = c("1 (20.43%)", "2 (1.75%)", "3 (6.41%)", 
                                 "4 (55.64%)", "5 (10.40%)", "6 (2.76%)", 
                                 "7 (1.67%)", "8 (0.94%)")))

indicator_labels <- c(
  "bul_c_plot"        = "Bullying C",
  "bul_s_plot"        = "Bullying S",
  "int_c_plot"        = "Intimidation C",
  "int_s_plot"        = "Intimidation S",
  "sex_c_plot"        = "Unwanted sexual attention C",
  "sex_s_plot"        = "Unwanted sexual attention S",
  "vio_c_plot"        = "Violence C",
  "vio_s_plot"        = "Violence S",
  "conflict_col_plot" = "Conflict C",
  "conflict_leid_plot"= "Conflict S",
  "steuncol_plot"     = "Incivility C",
  "steunleid_plot"    = "Incivility S",
  "psyveil_plot"      = "Psychological unsafety"
)

ggplot(plot_data8, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "1 (20.43%)" = "#0072B2",
      "2 (1.75%)"  = "#D55E00",
      "3 (6.41%)"  = "#009E73",
      "4 (55.64%)" = "#56B4E9",
      "5 (10.40%)" = "#CC79A7",
      "6 (2.76%)"  = "#E69F00",
      "7 (1.67%)"  = "#000000",
      "8 (0.94%)"  = "#F0E442"
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )
```


## Model9


```{r plot 9, echo=TRUE}
model9_bpred <- model9_b$predclass
NEA2022$model9_bpred <- model9_b$predclass
table(model9_b$predclass)
prop.table(table(model9_b$predclass)) * 100

vars <- c("bul_c_plot", "bul_s_plot", "int_c_plot", "int_s_plot",
          "vio_c_plot", "vio_s_plot", "sex_c_plot", "sex_s_plot",
          "conflict_col_plot", "conflict_leid_plot", 
          "steuncol_plot", "steunleid_plot", "psyveil_plot")

plot_data9 <- NEA2022 %>%
  pivot_longer(cols = all_of(vars), names_to = "indicator", values_to = "value") %>%
  group_by(model9_bpred, indicator) %>%
  summarise(mean_value = mean(value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    indicator   = factor(indicator, levels = vars),
    class_label = recode(as.character(model9_bpred), 
                         "1" = "1 (11.33%)", 
                         "2" = "2 (2.16%)", 
                         "3" = "3 (5.62%)", 
                         "4" = "4 (1.63%)",
                         "5" = "5 (0.38%)",
                         "6" = "6 (1.60%)",
                         "7" = "7 (55.82%)",
                         "8" = "8 (20.40%)",
                         "9" = "9 (1.06%)")
  ) %>% 
  mutate(class_label = factor(class_label,
                      levels = c("1 (11.33%)", "2 (2.16%)", "3 (5.62%)", "4 (1.63%)",
                                 "5 (0.38%)", "6 (1.60%)", "7 (55.82%)", 
                                 "8 (20.40%)", "9 (1.06%)")))

indicator_labels <- c(
  "bul_c_plot"        = "Bullying C",
  "bul_s_plot"        = "Bullying S",
  "int_c_plot"        = "Intimidation C",
  "int_s_plot"        = "Intimidation S",
  "sex_c_plot"        = "Unwanted sexual attention C",
  "sex_s_plot"        = "Unwanted sexual attention S",
  "vio_c_plot"        = "Violence C",
  "vio_s_plot"        = "Violence S",
  "conflict_col_plot" = "Conflict C",
  "conflict_leid_plot"= "Conflict S",
  "steuncol_plot"     = "Incivility C",
  "steunleid_plot"    = "Incivility S",
  "psyveil_plot"      = "Psychological unsafety"
)

ggplot(plot_data9, aes(x = indicator, y = mean_value,
                       color = class_label, group = class_label)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_discrete(labels = indicator_labels) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
                     limits = c(0, 1),
                     expand = c(0,0)) +
  scale_color_manual(
    values = c(
      "1 (11.33%)" = "#CC79A7",
      "2 (2.16%)"  = "#E69F00",
      "3 (5.62%)"  = "#009E73",
      "4 (1.63%)"  = "#000000",
      "5 (0.38%)"  = "#999999",
      "6 (1.60%)"  = "#D55E00",
      "7 (55.82%)" = "#56B4E9",
      "8 (20.40%)" = "#0072B2",
      "9 (1.06%)"  = "#F0E442"
    )
  ) +
  labs(x = NULL, y = "Mean score", color = NULL) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 11)
  )
```
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("LCA_binair.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
